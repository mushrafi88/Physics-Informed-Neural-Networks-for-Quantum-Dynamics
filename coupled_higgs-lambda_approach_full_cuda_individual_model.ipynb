{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc7a86c-65ae-45a3-97c5-67029d2b1726",
   "metadata": {},
   "source": [
    "# Coupled higgs equation \n",
    "$$\n",
    "u_{tt} - u_{xx} + |u|^2 u - 2uv = 0\n",
    "$$\n",
    "$$\n",
    "v_{tt} + v_{xx} - (\\left| u \\right|^2)_{xx} = 0\n",
    "$$\n",
    "\n",
    "where, $ u(x,t) $ represents a complex nucleon field and $ v(x,t) $ represents a real scalar meson field. The coupled Higgs field Equation describes a system of conserved scalar nucleon interaction with a neutral scalar meson.\n",
    "\n",
    "solutions \n",
    "\n",
    "$$\n",
    "u_1(x, t) = ir e^{ir(\\omega x + t)} \\sqrt{1 + \\omega^2} \\tanh\\left(\\frac{r(k + x + \\omega t)}{\\sqrt{2}}\\right)\n",
    "$$\n",
    "$$\n",
    "v_1(x, t) = r^2 \\tanh^2\\left(\\frac{r(k + x + \\omega t)}{\\sqrt{2}}\\right)\n",
    "$$\n",
    "\n",
    "for $t = 0$\n",
    "\n",
    "$$\n",
    "u_1(x, 0) = ir e^{ir \\omega x} \\sqrt{1 + \\omega^2} \\tanh\\left(\\frac{r(k + x)}{\\sqrt{2}}\\right)\n",
    "$$\n",
    "$$\n",
    "v_1(x, 0) = r^2 \\tanh^2\\left(\\frac{r(k + x)}{\\sqrt{2}}\\right)\n",
    "$$\n",
    "\n",
    "where \n",
    "$k = 4, \\omega = 5 , \\alpha = 2, c = 2, r = 2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "658356fb-2ccd-48d1-9492-b36716da03e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import LBFGS\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bf1fae9-619d-43f2-bf86-c80d0611c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Base class for shared functionalities\n",
    "class BaseNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseNN, self).__init__()\n",
    "\n",
    "    def _make_layers(self, in_features, out_features, num_layers, activation):\n",
    "        layers = [nn.Linear(in_features, out_features), activation()]\n",
    "        for _ in range(1, num_layers):\n",
    "            layers += [nn.Linear(out_features, out_features), activation()]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "# Model for U1 Real and U1 Imaginary\n",
    "class ModelU1(BaseNN):\n",
    "    def __init__(self, input_dim=2, units=64, output_dim=1, layers=3, activation=nn.Tanh):\n",
    "        super(ModelU1, self).__init__()\n",
    "        self.layers = self._make_layers(input_dim, units, layers, activation)\n",
    "        self.final = nn.Linear(units, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.final(self.layers(x))\n",
    "\n",
    "# Model for V1 with potential adaptations for functions like sinc\n",
    "class ModelV1(BaseNN):\n",
    "    def __init__(self, input_dim=2, units=64, output_dim=1, layers=2, activation=nn.Tanh):\n",
    "        super(ModelV1, self).__init__()\n",
    "        # Possible adjustment for sinc-like behavior could be modifying the layer depth or activation functions\n",
    "        self.layers = self._make_layers(input_dim, units, layers, activation)\n",
    "        self.final = nn.Linear(units, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.final(self.layers(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c738f3c7-f37f-4645-af7f-8feea7af94c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(x, t):\n",
    "    return torch.autograd.grad(x, t, grad_outputs=torch.ones_like(x), create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "def laplacian(field, x, t):\n",
    "    field_x = grad(field, x)\n",
    "    field_xx = grad(field_x, x)\n",
    "    field_t = grad(field, t)\n",
    "    field_tt = grad(field_t, t)\n",
    "    return field_xx, field_tt\n",
    "\n",
    "# Define the ODE system for the Coupled Higgs field equations\n",
    "def coupled_higgs(u_real, u_imag, v, x, t):\n",
    "    u_r_xx, u_r_tt = laplacian(u_real, x, t)\n",
    "    u_i_xx, u_i_tt = laplacian(u_imag, x, t)\n",
    "    v_xx, v_tt = laplacian(v, x, t)\n",
    "\n",
    "    # Calculate |u|^2 = u_real^2 + u_imag^2 and its second derivative w.r.t x\n",
    "    u_magnitude_squared = torch.square(u_real) + torch.square(u_imag)\n",
    "    u_magnitude_squared_xx, _ = laplacian(u_magnitude_squared, x, t)\n",
    "    \n",
    "    # Calculate residuals based on the differential equations\n",
    "    residual_u_real = u_r_tt - u_r_xx + u_magnitude_squared * u_real - 2 * u_real * v\n",
    "    residual_u_imag = u_i_tt - u_i_xx + u_magnitude_squared * u_imag - 2 * u_imag * v\n",
    "    residual_v = v_tt + v_xx - u_magnitude_squared_xx\n",
    "\n",
    "    return residual_u_real, residual_u_imag, residual_v\n",
    "\n",
    "# Function to calculate the real part of u1\n",
    "def real_u1(x, t, k, omega, r):\n",
    "    complex_exp = torch.exp(1j * r * (omega * x + t))\n",
    "    tanh_val = torch.tanh((r * (k + x + omega * t)) / torch.sqrt(torch.tensor(2.0)))\n",
    "    result = torch.real(1j * r * complex_exp * torch.sqrt(torch.tensor(1) + omega**2) * tanh_val)\n",
    "    return result\n",
    "\n",
    "def imag_u1(x, t, k, omega, r):\n",
    "    complex_exp = torch.exp(1j * r * (omega * x + t))\n",
    "    tanh_val = torch.tanh((r * (k + x + omega * t)) / torch.sqrt(torch.tensor(2.0)))\n",
    "    result = torch.imag(1j * r * complex_exp * torch.sqrt(torch.tensor(1) + omega**2) * tanh_val)\n",
    "    return result\n",
    "\n",
    "def real_v1(x, t, k, omega, r):\n",
    "    result = (r * torch.tanh((r * (k + x + omega * t)) / torch.sqrt(torch.tensor(2.0))))**2\n",
    "    return result\n",
    "\n",
    "def compute_analytical_boundary_ur_loss(model, x_boundary, t_boundary, mse_cost_function, k, omega, r):\n",
    "    x_t_boundary = torch.cat([x_boundary, t_boundary], dim=1)     \n",
    "    pred_u_r = model(x_t_boundary)\n",
    "    real_u1_val = real_u1(x_boundary, t_boundary, k, omega, r)\n",
    "    boundary_loss_ur = mse_cost_function(pred_u_r, real_u1_val)\n",
    "    return boundary_loss_ur\n",
    "\n",
    "def compute_analytical_boundary_ui_loss(model, x_boundary, t_boundary, mse_cost_function, k, omega, r):\n",
    "    x_t_boundary = torch.cat([x_boundary, t_boundary], dim=1)     \n",
    "    pred_u_i = model(x_t_boundary)\n",
    "    imag_u1_val = imag_u1(x_boundary, t_boundary, k, omega, r)\n",
    "    boundary_loss_ui = mse_cost_function(pred_u_i, imag_u1_val)\n",
    "    return boundary_loss_ui\n",
    "\n",
    "def compute_analytical_boundary_v_loss(model, x_boundary, t_boundary, mse_cost_function, k, omega, r):\n",
    "    x_t_boundary = torch.cat([x_boundary, t_boundary], dim=1)     \n",
    "    pred_v  = model(x_t_boundary)\n",
    "    real_v1_val = real_v1(x_boundary, t_boundary, k, omega, r)\n",
    "    boundary_loss_v = mse_cost_function(pred_v, real_v1_val)\n",
    "    \n",
    "    return boundary_loss_v\n",
    "\n",
    "def compute_physics_loss(model1, model2, model3, x, t, mse_cost_function):\n",
    "    x.requires_grad = True\n",
    "    t.requires_grad = True\n",
    "    x_t = torch.cat([x, t], dim=1) \n",
    "    pred_u_r = model1(x_t)\n",
    "    pred_u_i = model2(x_t)\n",
    "    pred_v   = model3(x_t)\n",
    "    \n",
    "    du_eq_r, du_eq_i, dv_eq = coupled_higgs(pred_u_r, pred_u_i, pred_v, x, t)\n",
    "    \n",
    "    zeros_r = torch.zeros_like(du_eq_r, device=device)\n",
    "    zeros_i = torch.zeros_like(du_eq_i, device=device)\n",
    "    zeros_v = torch.zeros_like(dv_eq, device=device)\n",
    "    \n",
    "    # Compute the MSE loss against zeros for each differential equation residual\n",
    "    loss_ur = mse_cost_function(du_eq_r, zeros_r)\n",
    "    loss_ui = mse_cost_function(du_eq_i, zeros_i)\n",
    "    loss_v = mse_cost_function(dv_eq, zeros_v)\n",
    "    \n",
    "    return loss_ur, loss_ui, loss_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "054a5b2b-1477-4d49-b696-e61487211c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Training on GPU.\n",
      "ModelV1(\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=64, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (3): Tanh()\n",
      "    (4): Linear(in_features=64, out_features=64, bias=True)\n",
      "    (5): Tanh()\n",
      "  )\n",
      "  (final): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and set the default device\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! Training on GPU.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Training on CPU.\")\n",
    "\n",
    "u1_real_model = ModelU1(input_dim=2, units=64, output_dim=1, layers=3, activation=nn.Tanh)\n",
    "u1_imag_model = ModelU1(input_dim=2, units=64, output_dim=1, layers=3, activation=nn.Tanh)\n",
    "v1_model = ModelV1(input_dim=2, units=64, output_dim=1, layers=3, activation=nn.Tanh)\n",
    "\n",
    "num_epochs = 100000  # Number of training epochs\n",
    "lr = 1e-3          # Learning rate\n",
    "num_samples = 1000 # Number of samples for training\n",
    "r = 1.1\n",
    "omega = 2\n",
    "k = 0.5\n",
    "factor = 1\n",
    "lambda_ = 1e-3\n",
    "\n",
    "optimizer_u1_real = Adam(u1_real_model.parameters(), lr=lr)\n",
    "optimizer_u1_imag = Adam(u1_imag_model.parameters(), lr=lr)\n",
    "optimizer_v1 = Adam(v1_model.parameters(), lr=lr)\n",
    "mse_cost_function = torch.nn.MSELoss()\n",
    "model_save_path = 'model_weights_testing_CHIGGS'\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "losses = []\n",
    "\n",
    "print(v1_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6f8248-42c7-4a79-b029-34ac42d3f9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "num_phases = 5\n",
    "epochs_per_phase = 5000\n",
    "num_samples = 1000\n",
    "\n",
    "for phase in range(num_phases):\n",
    "    # Adjust the range for x_n and t_n based on the current phase\n",
    "    lower_bound = phase * 0.2\n",
    "    upper_bound = (phase + 1) * 0.2\n",
    "    \n",
    "    for epoch in tqdm(range(epochs_per_phase),\n",
    "                      desc=f'Phase {phase+1} Progress:',  # Description includes current phase\n",
    "                      leave=False,  # Do not leave the progress bar when done\n",
    "                      ncols=75,  # Width of the progress bar\n",
    "                      mininterval=0.1,\n",
    "                      bar_format='{l_bar}{bar}|{remaining}',  # Only show the bar without any counters\n",
    "                      colour='blue'):\n",
    "        # Adjust the sampling of x_n and t_n within the new range\n",
    "        x_n = (torch.rand(num_samples, 1) * (upper_bound - lower_bound) + lower_bound).to(device)\n",
    "        t_n = (torch.rand(num_samples, 1) * (upper_bound - lower_bound) + lower_bound).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        physics_loss_ur, physics_loss_ui, physics_loss_v = compute_physics_loss(u1_real_model, u1_imag_model, v1_model, x_n, t_n, mse_cost_function)\n",
    "        domain_loss_ur_t, domain_loss_ui_t, domain_loss_v_t = compute_analytical_boundary_loss(u1_real_model, u1_imag_model, v1_model, x_n, t_n, mse_cost_function, k, omega, r)\n",
    "        loss_u = physics_loss_ur + physics_loss_ui + domain_loss_ur_t + domain_loss_ui_t\n",
    "        loss_v = physics_loss_v + domain_loss_v_t\n",
    "\n",
    "        total_loss = loss_u + loss_v \n",
    "        total_loss.backward()\n",
    "        \n",
    "        # Print loss every few epochs within each phase\n",
    "        if epoch % 1000 == 0 or epoch == epochs_per_phase - 1:  # Also print on the last epoch of the phase\n",
    "            print(f'Phase {phase+1}, Epoch {epoch}, Loss U: {loss_u.item()}, Loss V: {loss_v.item()}, Total Loss: {total_loss.item()}')\n",
    "        \n",
    "model_filename = os.path.join(model_save_path, f'C_HIGGS_shared_1.pth')\n",
    "torch.save(model.state_dict(), model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4220620b-b2b9-45f6-90d6-8e6c63ded157",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(model_save_path, 'C_HIGGS_shared_1.pth')\n",
    "model = CombinedModel(input_dim=2, shared_units=128, branch_units_u=64, branch_units_v=32, output_dim=1, shared_layers=2, branch_layers_u=4, branch_layers_v=2, activation=nn.Tanh).to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.train().to(device)\n",
    "\n",
    "num_epochs = 100000  # Number of training epochs\n",
    "lr = 1e-3          # Learning rate\n",
    "num_samples = 1000 # Number of samples for training\n",
    "r = 1.1\n",
    "omega = 2\n",
    "k = 0.5\n",
    "factor = 1\n",
    "lambda_ = 1e-3\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "for epoch in tqdm(range(num_epochs),\n",
    "                  desc='Progress:',  # Empty description\n",
    "                  leave=False,  # Do not leave the progress bar when done\n",
    "                  ncols=75,  # Width of the progress bar\n",
    "                  mininterval=0.1,\n",
    "                  bar_format='{l_bar}{bar}|{remaining}',  # Only show the bar without any counters\n",
    "                  colour='blue'):\n",
    "    x_n = (torch.rand(num_samples, 1)*factor).to(device)  # x in range [-5, -3]\n",
    "    t_n = (torch.rand(num_samples, 1)*factor).to(device)   \n",
    "    x_bc_x0 = torch.zeros((num_samples, 1)).to(device)\n",
    "    t_bc_x0 = torch.rand((num_samples, 1)).to(device)  # Uniformly distributed random values between 0 and 1\n",
    "    x_bc_x1 = torch.ones((num_samples, 1)).to(device)\n",
    "    t_bc_x1 = torch.rand((num_samples, 1)).to(device)  # Uniformly distributed random values between 0 and 1\n",
    "    x_bc_t0 = torch.rand((num_samples, 1)).to(device)  # Uniformly distributed random values between 0 and 1\n",
    "    t_bc_t0 = torch.zeros((num_samples, 1)).to(device)\n",
    "    x_bc_t1 = torch.rand((num_samples, 1)).to(device)  # Uniformly distributed random values between 0 and 1\n",
    "    t_bc_t1 = torch.ones((num_samples, 1)).to(device)\n",
    "    \n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    physics_loss_ur, physics_loss_ui, physics_loss_v = compute_physics_loss(model, x_n, t_n, mse_cost_function)\n",
    "    boundary_loss_ur_x0, boundary_loss_ui_x0, boundary_loss_v_x0 = compute_analytical_boundary_loss(model, x_bc_x0, t_bc_x0, mse_cost_function, k, omega, r)\n",
    "    boundary_loss_ur_x1, boundary_loss_ui_x1, boundary_loss_v_x1 = compute_analytical_boundary_loss(model, x_bc_x1, t_bc_x1, mse_cost_function, k, omega, r)\n",
    "    boundary_loss_ur_t0, boundary_loss_ui_t0, boundary_loss_v_t0 = compute_analytical_boundary_loss(model, x_bc_t0, t_bc_t0, mse_cost_function, k, omega, r)\n",
    "    #boundary_loss_ur_t1, boundary_loss_ui_t1, boundary_loss_v_t1 = compute_analytical_boundary_loss(model_u1, model_v1, x_bc_t1, t_bc_t1, mse_cost_function, k, omega, r)\n",
    "    domain_loss_ur_t, domain_loss_ui_t, domain_loss_v_t = compute_analytical_boundary_loss(model, x_n, t_n, mse_cost_function, k, omega, r)\n",
    "\n",
    "    loss_u = lambda_*(physics_loss_ur + physics_loss_ui + domain_loss_ur_t + domain_loss_ui_t) + (1-lambda_)*(boundary_loss_ur_x0 + boundary_loss_ui_x0 + boundary_loss_ur_x1 + boundary_loss_ui_x1 + boundary_loss_ur_t0 + boundary_loss_ui_t0)\n",
    "    loss_v = lambda_*(physics_loss_v + domain_loss_v_t) + (1-lambda_)*(boundary_loss_v_x0 + boundary_loss_v_x1 + boundary_loss_v_t0)\n",
    "    total_loss = loss_u + loss_v \n",
    "    \n",
    "    total_loss = loss_u + loss_v \n",
    "    total_loss.backward()\n",
    "    # Print loss every few epochs\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Epoch {epoch}, Loss U: {loss_u.item()}, Loss V: {loss_v.item()}')\n",
    "        model_filename = os.path.join(model_save_path, f'C_HIGGS_shared_epoch_{epoch}.pth')\n",
    "        torch.save(model.state_dict(), model_filename)\n",
    "        \n",
    "        df_losses = pd.DataFrame(losses)\n",
    "        csv_file_path = 'loss_data/C_HIGGS_training_losses.csv'\n",
    "        df_losses.to_csv(csv_file_path, index=False)\n",
    "    \n",
    "    if total_loss.item() < 1e-4:\n",
    "        print(f'Stopping early at epoch {epoch} due to reaching target loss.')\n",
    "        model_filename = os.path.join(model_save_path, f'C_HIGGS_shared_epoch_{epoch}.pth')\n",
    "        torch.save(model.state_dict(), model_filename)\n",
    "        break\n",
    "    \n",
    "    losses.append({\n",
    "        'Epoch': epoch,\n",
    "        'Loss U': loss_u.item(),\n",
    "        'Loss V': loss_v.item(),\n",
    "        'Total Loss': total_loss.item(),\n",
    "        #'Physics Loss': physics_loss_u.item() + physics_loss_v.item(),\n",
    "        #'Boundary Loss U': boundary_loss_u_x0.item() + boundary_loss_u_x1.item() + boundary_loss_u_t0.item() + boundary_loss_u_t1.item(),\n",
    "        #'Boundary Loss V': boundary_loss_v_x0.item() + boundary_loss_v_x1.item() + boundary_loss_v_t0.item() + boundary_loss_v_t1.item(),\n",
    "        #'Domain Loss U': domain_loss_u_t.item(),\n",
    "        #'Domain Loss V': domain_loss_v_t.item()\n",
    "    })\n",
    "\n",
    "model_filename = os.path.join(model_save_path, f'C_HIGGS_shared_final.pth')\n",
    "torch.save(model.state_dict(), model_filename)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41415efe-af94-4990-aae2-740568842f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Generate a grid of x and t values\n",
    "x = torch.linspace(0, 1, 400)  # More points for a smoother plot\n",
    "t = torch.linspace(0, 1, 400)\n",
    "X, T = torch.meshgrid(x, t)\n",
    "X_flat = X.flatten()\n",
    "T_flat = T.flatten()\n",
    "omega = 1\n",
    "#epoch = 21000\n",
    "\n",
    "# Convert to torch tensors and prepare for the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "x_t = torch.stack([X_flat, T_flat], dim=1).to(device).float()\n",
    "\n",
    "# Assuming shared_model is defined and loaded with trained parameters\n",
    "model_u1_state = torch.load(os.path.join(model_save_path, f'C_HIGGS_U1_epoch_{epoch}.pth'), map_location=device)\n",
    "model_v1_state = torch.load(os.path.join(model_save_path, f'C_HIGGS_V1_epoch_{epoch}.pth'), map_location=device)\n",
    "model_u1.load_state_dict(model_u1_state)\n",
    "model_v1.load_state_dict(model_v1_state)\n",
    "model_u1.eval()\n",
    "model_v1.eval()\n",
    "# Get predictions from the trained models\n",
    "with torch.no_grad():\n",
    "    pred_u_r, pred_u_i = model_u1(x_t)\n",
    "    pred_v = model_v1(x_t)\n",
    "\n",
    "# Calculate the analytical solutions\n",
    "real_u1_analytical = real_u1(X, T, k, omega, r)\n",
    "imag_u1_analytical = imag_u1(X, T, k, omega, r)\n",
    "real_v1_analytical = real_v1(X, T, k, omega, r)\n",
    "\n",
    "# Convert predictions and analytical solutions back to NumPy for plotting\n",
    "pred_u_r = pred_u_r.cpu().numpy().reshape(X.shape)\n",
    "pred_u_i = pred_u_i.cpu().numpy().reshape(X.shape)\n",
    "pred_v = pred_v.cpu().numpy().reshape(X.shape)\n",
    "real_u1_analytical = real_u1_analytical.cpu().numpy().reshape(X.shape)\n",
    "imag_u1_analytical = imag_u1_analytical.cpu().numpy().reshape(X.shape)\n",
    "real_v1_analytical = real_v1_analytical.cpu().numpy().reshape(X.shape)\n",
    "\n",
    "\n",
    "# Plotting\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "# Plot predicted and analytical real part of u1\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "surf1 = ax1.plot_surface(X, T, pred_u_r, cmap='viridis')\n",
    "fig.colorbar(surf1, ax=ax1, shrink=0.5, aspect=5)\n",
    "ax1.set_title('Predicted Real Part of $u_1(x, t)$')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('t')\n",
    "ax1.set_zlabel('Real part of $u_1$')\n",
    "\n",
    "# Plot predicted and analytical imaginary part of u1\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "surf2 = ax2.plot_surface(X, T, pred_u_i, cmap='viridis')\n",
    "fig.colorbar(surf2, ax=ax2, shrink=0.5, aspect=5)\n",
    "ax2.set_title('Predicted Imaginary Part of $u_1(x, t)$')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('t')\n",
    "ax2.set_zlabel('Imag part of $u_1$')\n",
    "\n",
    "# Plot predicted and analytical real part of v1\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "surf3 = ax3.plot_surface(X, T, pred_v, cmap='viridis')\n",
    "fig.colorbar(surf3, ax=ax3, shrink=0.5, aspect=5)\n",
    "ax3.set_title('Predicted Real Part of $v_1(x, t)$')\n",
    "ax3.set_xlabel('x')\n",
    "ax3.set_ylabel('t')\n",
    "ax3.set_zlabel('Real part of $v_1$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotting\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "# Plot predicted and analytical real part of u1\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "surf1 = ax1.plot_surface(X, T, real_u1_analytical, cmap='viridis')\n",
    "fig.colorbar(surf1, ax=ax1, shrink=0.5, aspect=5)\n",
    "ax1.set_title('Analytical Real Part of $u_1(x, t)$')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('t')\n",
    "ax1.set_zlabel('Real part of $u_1$')\n",
    "\n",
    "# Plot predicted and analytical imaginary part of u1\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "surf2 = ax2.plot_surface(X, T, imag_u1_analytical, cmap='viridis')\n",
    "fig.colorbar(surf2, ax=ax2, shrink=0.5, aspect=5)\n",
    "ax2.set_title('Analytical Imaginary Part of $u_1(x, t)$')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('t')\n",
    "ax2.set_zlabel('Imag part of $u_1$')\n",
    "\n",
    "# Plot predicted and analytical real part of v1\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "surf3 = ax3.plot_surface(X, T, real_v1_analytical, cmap='viridis')\n",
    "fig.colorbar(surf3, ax=ax3, shrink=0.5, aspect=5)\n",
    "ax3.set_title('Analytical Real Part of $v_1(x, t)$')\n",
    "ax3.set_xlabel('x')\n",
    "ax3.set_ylabel('t')\n",
    "ax3.set_zlabel('Real part of $v_1$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc963982-ee65-4af3-80c9-00804a8996d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
