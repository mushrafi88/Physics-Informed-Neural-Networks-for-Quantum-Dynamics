{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad2ddd4-26a5-4447-bb5e-7693b9b3185d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "from torch.optim import AdamW, LBFGS\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from itertools import cycle \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e9f9d8-cbe2-44cf-9b8a-e400cdae858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_features(x, B):\n",
    "    x_transformed = torch.matmul(x, B)\n",
    "    return torch.cat([torch.sin(x_transformed), torch.cos(x_transformed)], dim=-1)\n",
    "\n",
    "def init_fixed_frequency_matrix(size, scale=1.0):\n",
    "    num_elements = size[0] * size[1]\n",
    "    lin_space = torch.linspace(-scale, scale, steps=num_elements)\n",
    "    B = lin_space.view(size).float()\n",
    "    return B\n",
    "\n",
    "class FourierFeatureNN(nn.Module):\n",
    "    def __init__(self, input_dim=1, shared_units=16, neuron_units=32, scale=1.0, \n",
    "                 activation=nn.Tanh, device='cpu'):\n",
    "        super(FourierFeatureNN, self).__init__()\n",
    "        self.Bx = init_fixed_frequency_matrix((input_dim, shared_units // 2), scale=scale).to(device)\n",
    "        self.Bt = init_fixed_frequency_matrix((input_dim, shared_units // 2), scale=scale).to(device)\n",
    "\n",
    "        # Define separate paths for x and t after Fourier transformation\n",
    "        self.path_x = nn.Sequential( \n",
    "            nn.Linear(shared_units, neuron_units),  # Adjusted from shared_units // 2 to shared_units\n",
    "            activation(),\n",
    "            nn.Linear(neuron_units, neuron_units),\n",
    "            activation(),\n",
    "            nn.Linear(neuron_units, neuron_units),\n",
    "            activation() )\n",
    "        self.path_t = nn.Sequential( \n",
    "            nn.Linear(shared_units, neuron_units),  # Same adjustment\n",
    "            activation(),\n",
    "            nn.Linear(neuron_units, neuron_units),\n",
    "            activation(),\n",
    "            nn.Linear(neuron_units, neuron_units),\n",
    "            activation() )\n",
    "\n",
    "        # Define separate FFN for u and v directly after the paths\n",
    "        self.ffn_u = nn.Sequential(\n",
    "            nn.Linear(neuron_units, neuron_units), activation(),\n",
    "            nn.Linear(neuron_units, neuron_units), activation(),\n",
    "            nn.Linear(neuron_units, 2)  # Outputs for u (real and imaginary parts)\n",
    "        )\n",
    "        self.ffn_v = nn.Sequential(\n",
    "            nn.Linear(neuron_units, neuron_units), activation(),\n",
    "            nn.Linear(neuron_units, neuron_units), activation(),\n",
    "            nn.Linear(neuron_units, 1)  # Output for v\n",
    "        )\n",
    "\n",
    "        self.apply(self.initialize_weights)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Apply Fourier feature transformations\n",
    "        x_fourier = fourier_features(x, self.Bx)\n",
    "        t_fourier = fourier_features(t, self.Bt)\n",
    "\n",
    "        # Pass through separate paths\n",
    "        x_path_output = self.path_x(x_fourier)\n",
    "        t_path_output = self.path_t(t_fourier)\n",
    "\n",
    "        # Pointwise multiplication of the separate path outputs\n",
    "        combined_features = x_path_output * t_path_output\n",
    "\n",
    "        # Directly pass through different FFNs for u and v\n",
    "        final_output_u = self.ffn_u(combined_features)\n",
    "        final_output_v = self.ffn_v(combined_features)\n",
    "\n",
    "        # Splitting the output for u into real and complex parts\n",
    "        output_1, output_2 = final_output_u.split(1, dim=-1)\n",
    "        output_3 = final_output_v\n",
    "        \n",
    "        return output_1, output_2, output_3\n",
    "\n",
    "    def initialize_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf33577-940a-4f3a-a754-858514cccf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(x, t):\n",
    "    return torch.autograd.grad(x, t, grad_outputs=torch.ones_like(x), create_graph=True)[0]\n",
    "\n",
    "def laplacian(field, x, t):\n",
    "    field_x = grad(field, x)\n",
    "    field_xx = grad(field_x, x)\n",
    "    field_t = grad(field, t)\n",
    "    field_tt = grad(field_t, t)\n",
    "    return field_xx, field_tt\n",
    "\n",
    "# Define the ODE system for the Coupled Higgs field equations\n",
    "def coupled_higgs(u_real, u_imag, v, x, t):\n",
    "    u_r_xx, u_r_tt = laplacian(u_real, x, t)\n",
    "    u_i_xx, u_i_tt = laplacian(u_imag, x, t)\n",
    "    v_xx, v_tt = laplacian(v, x, t)\n",
    "\n",
    "    u_abs = torch.square(u_real) + torch.square(u_imag)\n",
    "    u_abs_xx, u_abs_tt = laplacian(u_abs, x, t)\n",
    "\n",
    "    # Calculate the field equations\n",
    "    du_r = u_r_tt - u_r_xx + u_abs * u_real - 2 * u_real * v\n",
    "    du_i = u_i_tt - u_i_xx + u_abs * u_imag - 2 * u_imag * v\n",
    "    dv = v_tt + v_xx - u_abs_xx\n",
    "    \n",
    "    return du_r**2, du_i**2, dv**2\n",
    "\n",
    "def real_u1(x, t, k, omega, r):\n",
    "    complex_exp = torch.exp(1j * r * (omega * x + t))\n",
    "    tanh_val = torch.tanh((r * (k + x + omega * t)) / torch.sqrt(torch.tensor(2.0)))\n",
    "    result = torch.real(1j * r * complex_exp * torch.sqrt(torch.tensor(1) + omega**2) * tanh_val)\n",
    "    return result\n",
    "\n",
    "def imag_u1(x, t, k, omega, r):\n",
    "    complex_exp = torch.exp(1j * r * (omega * x + t))\n",
    "    tanh_val = torch.tanh((r * (k + x + omega * t)) / torch.sqrt(torch.tensor(2.0)))\n",
    "    result = torch.imag(1j * r * complex_exp * torch.sqrt(torch.tensor(1) + omega**2) * tanh_val)\n",
    "    return result\n",
    "\n",
    "def real_v1(x, t, k, omega, r):\n",
    "    result = (r * torch.tanh((r * (k + x + omega * t)) / torch.sqrt(torch.tensor(2.0))))**2\n",
    "    return result\n",
    "\n",
    "def compute_analytical_boundary_loss(model, x, t, mse_cost_function, k, omega, r):\n",
    "    pred_u_r, pred_u_i, pred_v = model(x, t)\n",
    "\n",
    "    real_u1_val = real_u1(x, t, k, omega, r)\n",
    "    imag_u1_val = imag_u1(x, t, k, omega, r)\n",
    "    real_v1_val = real_v1(x, t, k, omega, r)\n",
    " \n",
    "    boundary_loss_ur = mse_cost_function(pred_u_r, real_u1_val)\n",
    "    boundary_loss_ui = mse_cost_function(pred_u_i, imag_u1_val)\n",
    "    boundary_loss_v = mse_cost_function(pred_v, real_v1_val)\n",
    "    \n",
    "    return boundary_loss_ur, boundary_loss_ui, boundary_loss_v\n",
    "\n",
    "def compute_physics_loss(model, x, t, device, mse_cost_function):\n",
    "    x.requires_grad = True\n",
    "    t.requires_grad = True\n",
    "    pred_u_r, pred_u_i, pred_v = model(x, t)\n",
    "    \n",
    "    # Compute the differential equation residuals\n",
    "    du_eq_r, du_eq_i, dv_eq = coupled_higgs(pred_u_r, pred_u_i, pred_v, x, t)\n",
    "    \n",
    "    # Define target tensors of zeros with the same shape as the predictions\n",
    "    zeros_r = torch.zeros_like(du_eq_r, device=device)\n",
    "    zeros_i = torch.zeros_like(du_eq_i, device=device)\n",
    "    zeros_v = torch.zeros_like(dv_eq, device=device)\n",
    "    \n",
    "    # Compute the MSE loss against zeros for each differential equation residual\n",
    "    loss_r = mse_cost_function(du_eq_r, zeros_r)\n",
    "    loss_i = mse_cost_function(du_eq_i, zeros_i)\n",
    "    loss_v = mse_cost_function(dv_eq, zeros_v)\n",
    "    \n",
    "    # Return the scalar loss values for real part, imaginary part, and v\n",
    "    return loss_r, loss_i, loss_v\n",
    "\n",
    "def cyclic_iterator(items):\n",
    "    return cycle(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab5257a-6959-4595-bb23-5443087fe570",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LBFGS_training(model, model_save_path, mse_cost_function, device, num_epochs, lr, num_samples, r, k, omega, gamma, line_search_fn):\n",
    "    print('Starting LBFGS Fine Tuning')\n",
    "    optimizer = LBFGS(model.parameters(), lr=1, max_iter=20, max_eval=None, tolerance_grad=1e-07, tolerance_change=1e-09, history_size=100, line_search_fn=line_search_fn)\n",
    "    factor = -2\n",
    "\n",
    "    x_n = (torch.rand(num_samples, 1)*4 + factor ).to(device)  # x in range [-5, -3]\n",
    "    t_n = (torch.rand(num_samples, 1)).to(device)   \n",
    "    x_dom = (torch.rand(num_samples, 1)*4 + factor ).to(device)\n",
    "    t_dom = torch.rand(num_samples, 1).to(device) \n",
    "    x_bc_x0 = (torch.zeros(num_samples, 1)*4 + factor ).to(device)\n",
    "    t_bc_x0 = torch.rand(num_samples, 1).to(device)  # Uniformly distributed random values between 0 and 1\n",
    "    x_bc_x1 = (torch.zeros(num_samples, 1)*4 - factor ).to(device)\n",
    "    t_bc_x1 = torch.rand(num_samples, 1).to(device)  # Uniformly distributed random values between 0 and 1\n",
    "    x_bc_t0 = (torch.rand(num_samples, 1)*4 + factor ).to(device)  # Uniformly distributed random values between 0 and 1\n",
    "    t_bc_t0 = torch.zeros(num_samples, 1).to(device)\n",
    "\n",
    "    for epoch in tqdm(range(num_epochs),\n",
    "                  desc='Progress:',  \n",
    "                  leave=False,  \n",
    "                  ncols=75,\n",
    "                  mininterval=0.1,\n",
    "                  bar_format='{l_bar} {bar} | {remaining}',  # Only show the bar without any counters\n",
    "                  colour='blue'): \n",
    "        model.train()\n",
    "        \n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            physics_loss_ur, physics_loss_ui, physics_loss_v = compute_physics_loss(model, x_n, t_n, device, mse_cost_function)\n",
    "            boundary_loss_ur_x0, boundary_loss_ui_x0, boundary_loss_v_x0 = compute_analytical_boundary_loss(model, x_bc_x0, t_bc_x0, mse_cost_function, k, omega, r)\n",
    "            boundary_loss_ur_x1, boundary_loss_ui_x1, boundary_loss_v_x1 = compute_analytical_boundary_loss(model, x_bc_x1, t_bc_x1, mse_cost_function, k, omega, r)\n",
    "            boundary_loss_ur_t0, boundary_loss_ui_t0, boundary_loss_v_t0 = compute_analytical_boundary_loss(model, x_bc_t0, t_bc_t0, mse_cost_function, k, omega, r)\n",
    "            # boundary_loss_ur_t1, boundary_loss_ui_t1, boundary_loss_v_t1 = compute_analytical_boundary_loss(model, x_bc_t1, t_bc_t1, mse_cost_function, k, omega, r)\n",
    "            domain_loss_ur_t, domain_loss_ui_t, domain_loss_v_t = compute_analytical_boundary_loss(model, x_dom, t_dom, mse_cost_function, k, omega, r)\n",
    "   \n",
    "            # Total loss \n",
    "            loss_ur = gamma*(physics_loss_ur) + (1-gamma)*( boundary_loss_ur_x0 + boundary_loss_ur_t0 + domain_loss_ur_t ) + (1-gamma)*0.01*( boundary_loss_ur_x1)\n",
    "            loss_ui = gamma*(physics_loss_ui) + (1-gamma)*( boundary_loss_ui_x0 + boundary_loss_ui_t0 + domain_loss_ui_t ) + (1-gamma)*0.01*( boundary_loss_ui_x1)\n",
    "            loss_v = gamma*(physics_loss_v) + (1-gamma)*( boundary_loss_v_x0 + boundary_loss_v_t0 + domain_loss_v_t ) + (1-gamma)*0.01*( boundary_loss_v_x1)\n",
    "            total_loss = loss_ur + loss_ui + loss_v\n",
    "            total_loss.backward()\n",
    "\n",
    "            return total_loss \n",
    "    \n",
    "        optimizer.step(closure)\n",
    "        if epoch % 10 == 0:\n",
    "            current_loss = closure()  # Optionally recompute to print\n",
    "            print(f' Epoch {epoch}, Loss: {current_loss.item()}') \n",
    "            model_filename = os.path.join(model_save_path, f'C_HIGGS_second_training_epoch_{epoch}.pth')\n",
    "            torch.save(model.state_dict(), model_filename)\n",
    "            plot_model_results(epoch, model, device, k, omega, r, sigma=1, cmap='viridis', image_save_path='results') \n",
    "            \n",
    "    model_filename = os.path.join(model_save_path, f'C_HIGGS_second_training.pth')\n",
    "    torch.save(model.state_dict(), model_filename)\n",
    "    print('TRAINING COMPLETED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb18d7cc-4719-4832-8506-8d3174de888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.ndimage import gaussian_filter\n",
    "\n",
    "def plot_model_results(epoch, model, device, k, omega, r, sigma=1, cmap='viridis', image_save_path='results'):\n",
    "    x = torch.linspace(-1.8, 1.8, 400)\n",
    "    t = torch.linspace(0.2, 0.8, 400)\n",
    "    X, T = torch.meshgrid(x, t)  # Create a 2D grid of x and t\n",
    "    X_flat = X.flatten().unsqueeze(-1).to(device)\n",
    "    T_flat = T.flatten().unsqueeze(-1).to(device)\n",
    "    \n",
    "    model_save_path = 'model_weights' \n",
    "    model_state = torch.load(os.path.join(model_save_path, f'C_HIGGS_second_training_epoch_{epoch}.pth'), map_location=device)\n",
    "    model.load_state_dict(model_state)\n",
    "    model.eval()\n",
    "\n",
    "    # Get predictions from the trained models\n",
    "    with torch.no_grad():\n",
    "        pred_u_r, pred_u_i, pred_v = model(X_flat, T_flat) \n",
    "\n",
    "    pred_u_r = pred_u_r.cpu().reshape(X.shape).numpy()\n",
    "    pred_u_i = pred_u_i.cpu().reshape(X.shape).numpy()\n",
    "    pred_v = pred_v.cpu().reshape(X.shape).numpy()\n",
    "\n",
    "    real_u1_analytical = real_u1(X_flat, T_flat, k, omega, r).cpu().reshape(X.shape).numpy()\n",
    "    imag_u1_analytical = imag_u1(X_flat, T_flat, k, omega, r).cpu().reshape(X.shape).numpy()\n",
    "    real_v1_analytical = real_v1(X_flat, T_flat, k, omega, r).cpu().reshape(X.shape).numpy()\n",
    "\n",
    "    pred_v_smooth = gaussian_filter(pred_v, sigma=sigma)\n",
    "\n",
    "    shrink = 0.3\n",
    "    aspect = 50\n",
    "\n",
    "    # Plotting predictions\n",
    "    fig = plt.figure(figsize=(24, 16))\n",
    "\n",
    "    ax1 = fig.add_subplot(231, projection='3d')\n",
    "    ax1.plot_surface(X.numpy(), T.numpy(), pred_u_r, cmap=cmap)\n",
    "    ax1.set_title('Predicted Real Part of $u_1(x, t)$')\n",
    "    ax1.set_xlabel('x')\n",
    "    ax1.set_ylabel('t')\n",
    "    ax1.set_zlabel('Real part of $u_1$')\n",
    "\n",
    "    ax2 = fig.add_subplot(232, projection='3d')\n",
    "    ax2.plot_surface(X.numpy(), T.numpy(), pred_u_i, cmap=cmap)\n",
    "    ax2.set_title('Predicted Imaginary Part of $u_1(x, t)$')\n",
    "    ax2.set_xlabel('x')\n",
    "    ax2.set_ylabel('t')\n",
    "    ax2.set_zlabel('Imag part of $u_1$')\n",
    "\n",
    "    ax3 = fig.add_subplot(233, projection='3d')\n",
    "    ax3.plot_surface(X.numpy(), T.numpy(), pred_v_smooth, cmap=cmap)\n",
    "    ax3.set_title('Predicted Real Part of $v_1(x, t)$')\n",
    "    ax3.set_xlabel('x')\n",
    "    ax3.set_ylabel('t')\n",
    "    ax3.set_zlabel('Real part of $v_1$')\n",
    "\n",
    "    ax4 = fig.add_subplot(234, projection='3d')\n",
    "    ax4.plot_surface(X.numpy(), T.numpy(), real_u1_analytical, cmap=cmap)\n",
    "    ax4.set_title('Analytical Real Part of $u_1(x, t)$')\n",
    "    ax4.set_xlabel('x')\n",
    "    ax4.set_ylabel('t')\n",
    "    ax4.set_zlabel('Real part of $u_1$')\n",
    "\n",
    "    ax5 = fig.add_subplot(235, projection='3d')\n",
    "    ax5.plot_surface(X.numpy(), T.numpy(), imag_u1_analytical, cmap=cmap)\n",
    "    ax5.set_title('Analytical Imaginary Part of $u_1(x, t)$')\n",
    "    ax5.set_xlabel('x')\n",
    "    ax5.set_ylabel('t')\n",
    "    ax5.set_zlabel('Imag part of $u_1$')\n",
    "\n",
    "    ax6 = fig.add_subplot(236, projection='3d')\n",
    "    ax6.plot_surface(X.numpy(), T.numpy(), real_v1_analytical, cmap=cmap)\n",
    "    ax6.set_title('Analytical Real Part of $v_1(x, t)$')\n",
    "    ax6.set_xlabel('x')\n",
    "    ax6.set_ylabel('t')\n",
    "    ax6.set_zlabel('Real part of $v_1$')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(image_save_path, f'chiggs_model_comparison_3d_epoch_{epoch}.png'))\n",
    "    plt.close(fig)  # Close the figure to free memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e64a9b-ec97-4750-b565-6d916c706d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! Training on GPU.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Training on CPU.\")\n",
    "\n",
    "model = FourierFeatureNN(device=device).to(device)\n",
    "\n",
    "print(model)\n",
    "num_epochs_lbfgs = 500  # Number of training epochs\n",
    "num_samples_lbfgs = 1000*3 # Number of samples for training\n",
    "num_epochs_sq = 36000\n",
    "num_samples_sq = 1000\n",
    "lr_sq = 1e-4 \n",
    "lr_lbfgs = 1e-3\n",
    "r = 1.1\n",
    "omega = 5 \n",
    "k = 0.5\n",
    "gamma = 1e-4\n",
    "model_save_path = 'model_weights' \n",
    "mse_cost_function = torch.nn.MSELoss()\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "losses = []\n",
    "line_search_fn = \"strong_wolfe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8663dca4-1f75-4867-8640-ff323f7ef06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LBFGS_training(model, model_save_path, mse_cost_function, device, num_epochs_lbfgs, lr_lbfgs, num_samples_lbfgs, r, k, omega, gamma, line_search_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
