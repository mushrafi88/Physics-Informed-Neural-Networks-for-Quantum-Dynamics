{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db451872-2c47-4b20-8484-79c59e65f200",
   "metadata": {},
   "source": [
    "# Coupled Spring System solve with initial conditions \n",
    "\n",
    "![image](images/Mass-spring-model-of-a-2-DOF-system-consisting-of-two-coupled-resonators.png)\n",
    "\n",
    "$$\n",
    "L = \\frac{1}{2} m_1 \\frac{d^2x_1}{dt^2} + \\frac{1}{2} m_2 \\frac{d^2x_2}{dt^2} - \\frac{1}{2}\\left(k_l x_1^2 + k_r x_2^2 + k_m (x_1 - x_2)^2\\right)\n",
    "$$\n",
    "\n",
    "1. For the first mass:\n",
    "$$\n",
    "\\frac{d}{dt} \\left( \\frac{dL}{dx_1} \\right) = -k_lx_1 - k_m(x_1 - x_2)\n",
    "$$\n",
    "\n",
    "2. And for the second mass:\n",
    "$$\n",
    "\\frac{d}{dt} \\left( \\frac{dL}{dx_2} \\right) = -k_rx_2 + k_m(x_1 - x_2)\n",
    "$$\n",
    "\n",
    "so the coupled differential equations are \n",
    "$$\n",
    "m_1 \\frac{d^2x_1}{dt^2} + (k_l + k_m) x_1 - k_m x_2 = 0\n",
    "$$\n",
    "and \n",
    "$$\n",
    "m_2 \\frac{d^2x_2}{dt^2} + (k_r + k_m) x_2 - k_m x_1 = 0\n",
    "$$\n",
    "\n",
    "let $ m_1 = 1, m_2 = 2, k_l = 0.5, k_r = 0.75, k_m = 1$\n",
    "so the equations become, \n",
    "$$\n",
    "\\frac{d^2x_1}{dt^2} = -1.5x_1 + x_2\n",
    "$$\n",
    "$$\n",
    "\\frac{d^2x_2}{dt^2} = -0.875x_2 + x_1\n",
    "$$\n",
    "We now proceed to solve the differential equations for various boundary conditions and assume \n",
    "$ -1 \\leq x_{1} \\leq 2$ and $ -2 \\leq x_{2} \\leq 1$ such that $L = 3$ and $ -1 \\leq v_{1} \\leq 1$, $ -1 \\leq v_{2} \\leq 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f876cea7-0fa1-4a67-b6ea-685bc8b5bd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.05306294932961464\n",
      "Epoch 1000, Loss: 0.022910848259925842\n",
      "Epoch 2000, Loss: 0.4846821129322052\n",
      "Epoch 3000, Loss: 0.19462203979492188\n",
      "Epoch 4000, Loss: 0.22618910670280457\n",
      "Epoch 5000, Loss: 0.01177764218300581\n",
      "Epoch 6000, Loss: 0.13835124671459198\n",
      "Epoch 7000, Loss: 0.018267080187797546\n",
      "Epoch 8000, Loss: 0.2298504263162613\n",
      "Epoch 9000, Loss: 0.1902030110359192\n",
      "Epoch 10000, Loss: 0.10836674273014069\n",
      "Epoch 11000, Loss: 0.10459430515766144\n",
      "Epoch 12000, Loss: 0.14901548624038696\n",
      "Epoch 13000, Loss: 0.05463700741529465\n",
      "Epoch 14000, Loss: 0.03009019047021866\n",
      "Epoch 15000, Loss: 0.17116054892539978\n",
      "Epoch 16000, Loss: 0.06472314894199371\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m ic_flat \u001b[38;5;241m=\u001b[39m ic\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m     55\u001b[0m states, t_eval_np \u001b[38;5;241m=\u001b[39m solve_ivps(ic_flat)\n\u001b[0;32m---> 56\u001b[0m states \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m t_eval \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(t_eval_np, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32, requires_grad\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# This is crucial\u001b[39;00m\n\u001b[1;32m     58\u001b[0m ic_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(ic, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "import numpy as np\n",
    "from scipy.integrate import solve_ivp\n",
    "\n",
    "class SimpleFFN(nn.Module):\n",
    "    \"\"\"\n",
    "    Defines a simple feedforward neural network (FFN) with one hidden layer.\n",
    "    - N_INPUT: Number of input features.\n",
    "    - N_OUTPUT: Number of output features.\n",
    "    - N_HIDDEN: Number of neurons in the hidden layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, N_INPUT, N_OUTPUT, N_HIDDEN):\n",
    "        super().__init__()\n",
    "        self.activation = nn.Tanh()\n",
    "        self.input_layer = nn.Linear(N_INPUT, N_HIDDEN)\n",
    "        self.output_layer = nn.Linear(N_HIDDEN, N_OUTPUT)\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.input_layer(x))        \n",
    "        x = self.output_layer(x)\n",
    "        return x\n",
    "# Example instantiation of the model\n",
    "\n",
    "def differential_equations(t, y):\n",
    "    x1, x2, v1, v2 = y\n",
    "    dx1dt = v1\n",
    "    dx2dt = v2\n",
    "    dv1dt = -1.5*x1 + x2\n",
    "    dv2dt = -0.875*x2 + x1\n",
    "    return [dx1dt, dx2dt, dv1dt, dv2dt]\n",
    "\n",
    "def solve_ivps(initial_conditions, t_span=[0, 1], t_eval=np.linspace(0, 1, 1000)):\n",
    "    sol = solve_ivp(differential_equations, t_span, initial_conditions, t_eval=t_eval, method='RK45')\n",
    "    return sol.y.T, sol.t\n",
    "\n",
    "def initial_conditions(batch_size=32):\n",
    "    x1_0 = np.random.uniform(-1, 2, (batch_size, 1))\n",
    "    x2_0 = np.random.uniform(-2, 1, (batch_size, 1))\n",
    "    v1_0 = np.random.uniform(-1, 1, (batch_size, 1))\n",
    "    v2_0 = np.random.uniform(-1, 1, (batch_size, 1))\n",
    "    return np.hstack((x1_0, x2_0, v1_0, v2_0))\n",
    "\n",
    "torch.manual_seed(123)\n",
    "model = SimpleFFN(5, 2, 10)  \n",
    "optimizer = Adam(model.parameters())\n",
    "\n",
    "for epoch in range(100000):\n",
    "    optimizer.zero_grad()\n",
    "    initials = initial_conditions(batch_size=1)  # For simplicity, batch_size=1\n",
    "    loss = 0\n",
    "    \n",
    "    for ic in initials:\n",
    "        ic_flat = ic.flatten()\n",
    "        states, t_eval_np = solve_ivps(ic_flat)\n",
    "        states = torch.tensor(states, dtype=torch.float32)\n",
    "        t_eval = torch.tensor(t_eval_np, dtype=torch.float32, requires_grad=True).view(-1, 1)  # This is crucial\n",
    "        ic_tensor = torch.tensor(ic, dtype=torch.float32)\n",
    "        model_input = torch.cat((t_eval, ic_tensor.repeat(len(t_eval), 1)), 1)\n",
    "        \n",
    "        x_pred = model(model_input)\n",
    "        \n",
    "        # Physics-informed loss: derivatives\n",
    "        x1_pred, x2_pred = x_pred[:, 0], x_pred[:, 1]\n",
    "        v1_pred = torch.autograd.grad(x1_pred.sum(), t_eval, create_graph=True)[0]\n",
    "        v2_pred = torch.autograd.grad(x2_pred.sum(), t_eval, create_graph=True)[0]\n",
    "        a1_pred = torch.autograd.grad(v1_pred.sum(), t_eval, create_graph=True)[0]\n",
    "        a2_pred = torch.autograd.grad(v2_pred.sum(), t_eval, create_graph=True)[0]\n",
    "        \n",
    "        # Loss\n",
    "        physics_loss = torch.mean((a1_pred + 1.5*x1_pred - x2_pred)**2) + torch.mean((a2_pred + 0.875*x2_pred - x1_pred)**2)\n",
    "        mse_loss = torch.mean((x_pred - states[:, :2])**2)        \n",
    "        total_loss = mse_loss + physics_loss\n",
    "        loss += total_loss\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de93eda-543f-4eb8-b1a2-defbca1a25b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
