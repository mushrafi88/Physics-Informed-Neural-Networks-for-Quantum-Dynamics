{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc7a86c-65ae-45a3-97c5-67029d2b1726",
   "metadata": {},
   "source": [
    "# Coupled higgs equation \n",
    "$$\n",
    "u_{tt} - u_{xx} + |u|^2 u - 2uv = 0\n",
    "$$\n",
    "$$\n",
    "v_{tt} + v_{xx} - (\\left| u \\right|^2)_{xx} = 0\n",
    "$$\n",
    "\n",
    "where, $ u(x,t) $ represents a complex nucleon field and $ v(x,t) $ represents a real scalar meson field. The coupled Higgs field Equation describes a system of conserved scalar nucleon interaction with a neutral scalar meson.\n",
    "\n",
    "solutions \n",
    "\n",
    "$$\n",
    "u_1(x, t) = ir e^{ir(\\omega x + t)} \\sqrt{1 + \\omega^2} \\tanh\\left(\\frac{r(k + x + \\omega t)}{\\sqrt{2}}\\right)\n",
    "$$\n",
    "$$\n",
    "v_1(x, t) = r^2 \\tanh^2\\left(\\frac{r(k + x + \\omega t)}{\\sqrt{2}}\\right)\n",
    "$$\n",
    "\n",
    "for $t = 0$\n",
    "\n",
    "$$\n",
    "u_1(x, 0) = ir e^{ir \\omega x} \\sqrt{1 + \\omega^2} \\tanh\\left(\\frac{r(k + x)}{\\sqrt{2}}\\right)\n",
    "$$\n",
    "$$\n",
    "v_1(x, 0) = r^2 \\tanh^2\\left(\\frac{r(k + x)}{\\sqrt{2}}\\right)\n",
    "$$\n",
    "\n",
    "where \n",
    "$k = 4, \\omega = 5 , \\alpha = 2, c = 2, r = 2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99781f47-c584-4a39-a506-fa461d0e3c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7fffe0978170>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.init as init\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f09cb347-6b88-4e53-9ad2-7b214fc78075",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_features(x, B):\n",
    "    x_transformed = torch.matmul(x, B)\n",
    "    return torch.cat([torch.sin(2 * torch.pi * x_transformed), torch.cos(2 * torch.pi * x_transformed)], dim=-1)\n",
    "\n",
    "def init_frequency_matrix(size, std_dev=1.0):\n",
    "    B = torch.normal(0, std_dev, size=size)\n",
    "    return B\n",
    "\n",
    "class FourierFeatureNN(nn.Module):\n",
    "    def __init__(self, input_dim=1, shared_units=128, output_dim=3, layers_per_path=2, std_dev=1.0, activation=nn.Tanh, device=device):\n",
    "        super(FourierFeatureNN, self).__init__()\n",
    "        self.Bx = init_frequency_matrix((input_dim, shared_units // 2), std_dev=std_dev).float().to(device)\n",
    "        self.Bt = init_frequency_matrix((input_dim, shared_units // 2), std_dev=std_dev).float().to(device)\n",
    "\n",
    "        # Separate paths for processing Fourier features of x and t with weighting\n",
    "        self.path_x_weights = nn.Sequential(\n",
    "            nn.Linear(shared_units, 256),\n",
    "            activation(),\n",
    "            nn.Linear(256, 128),\n",
    "            activation(),\n",
    "            nn.Linear(128, 64),\n",
    "            activation()\n",
    "        )\n",
    "\n",
    "        for layer in self.path_x_weights:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                init.xavier_uniform_(layer.weight)\n",
    "                if layer.bias is not None:\n",
    "                    init.zeros_(layer.bias)\n",
    "\n",
    "        # And a similar structure for t, but with different sizes as an example\n",
    "        self.path_t_weights = nn.Sequential(\n",
    "            nn.Linear(shared_units, 256),\n",
    "            activation(),\n",
    "            nn.Linear(256, 128),\n",
    "            activation(),\n",
    "            nn.Linear(128, 64),\n",
    "            activation()\n",
    "        )\n",
    "\n",
    "        # Repeat weight initialization for path_t_weights\n",
    "        for layer in self.path_t_weights:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                init.xavier_uniform_(layer.weight)\n",
    "                if layer.bias is not None:\n",
    "                    init.zeros_(layer.bias)\n",
    "                    \n",
    "        self.combine_and_output = nn.Sequential(\n",
    "            nn.Linear(64, 32),  # Assuming we're combining the last layers of path_x and path_t\n",
    "            activation(),\n",
    "            nn.Linear(32, 16),\n",
    "            activation(),\n",
    "            nn.Linear(16, output_dim)  # Output dimension remains 3 (u_real, u_imag, v)\n",
    "        )\n",
    "\n",
    "        for layer in self.combine_and_output:\n",
    "            if isinstance(layer, nn.Linear):\n",
    "                init.xavier_uniform_(layer.weight)\n",
    "                if layer.bias is not None:\n",
    "                    init.zeros_(layer.bias)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Transform x and t into Fourier features\n",
    "        x_fourier = fourier_features(x, self.Bx)\n",
    "        t_fourier = fourier_features(t, self.Bt)\n",
    "\n",
    "        # Get weighted Fourier features for x and t\n",
    "        weighted_x = self.path_x_weights(x_fourier)\n",
    "        weighted_t = self.path_t_weights(t_fourier)\n",
    "\n",
    "        # Element-wise multiplication of weighted Fourier features of x and t\n",
    "        combined_features = weighted_x * weighted_t\n",
    "\n",
    "        # Produce u_real, u_imag, and v by passing combined features through final layer\n",
    "        output = self.combine_and_output(combined_features)\n",
    "        u_real, u_imag, v = output[:, 0], output[:, 1], output[:, 2]\n",
    "\n",
    "        return u_real.view(-1, 1), u_imag.view(-1, 1), v.view(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45afabba-d0ef-437d-8d55-fb6de0e5e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(y, x):\n",
    "    return torch.autograd.grad(y, x, grad_outputs=torch.ones_like(y), create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "def laplacian(field, x, t):\n",
    "    field_x = grad(field, x)\n",
    "    field_xx = grad(field_x, x)\n",
    "    field_t = grad(field, t)\n",
    "    field_tt = grad(field_t, t)\n",
    "    return field_xx, field_tt\n",
    "\n",
    "# Define the ODE system for the Coupled Higgs field equations\n",
    "def coupled_higgs(u_real, u_imag, v, x, t):\n",
    "    u_r_xx, u_r_tt = laplacian(u_real, x, t)\n",
    "    u_i_xx, u_i_tt = laplacian(u_imag, x, t)\n",
    "    v_xx, v_tt = laplacian(v, x, t)\n",
    "\n",
    "    u_abs = u_real**2 + u_imag**2\n",
    "    u_abs_xx, u_abs_tt = laplacian(u_abs, x, t)\n",
    "\n",
    "    # Calculate the field equations\n",
    "    du_eq_r = u_r_tt - u_r_xx + u_abs * u_real - 2 * u_real * v\n",
    "    du_eq_i = u_i_tt - u_i_xx + u_abs * u_imag - 2 * u_imag * v\n",
    "    dv_eq = v_tt + v_xx - u_abs_xx\n",
    "    \n",
    "    return du_eq_r, du_eq_i, dv_eq\n",
    "\n",
    "# Function to calculate the real part of u1\n",
    "def real_u1(x, t, k, omega, r):\n",
    "    return np.real(1j * r * np.exp(1j * r * (omega * x + t)) * np.sqrt(1 + omega**2) *\n",
    "                   np.tanh( (r * (k + x + omega * t)) / np.sqrt(2) ) )\n",
    "\n",
    "def imag_u1(x, t, k, omega, r):\n",
    "    return np.imag(1j * r * np.exp(1j * r * (omega * x + t)) * np.sqrt(1 + omega**2) *\n",
    "                   np.tanh((r * (k + x + omega * t)) / np.sqrt(2) ) )\n",
    "    \n",
    "def real_v1(x, t, k, omega, r):\n",
    "    return (r * np.tanh((r * (k + x + omega * t)) / np.sqrt(2)) )**2\n",
    "\n",
    "def compute_analytical_boundary_loss(model, x_boundary, t_boundary, mse_cost_function, k, omega, r):\n",
    "    x = torch.from_numpy(x_boundary).float().to(device)\n",
    "    t = torch.from_numpy(t_boundary).float().to(device)\n",
    "    pred_u_r, pred_u_i, pred_v = model(x, t)\n",
    "\n",
    "    real_u1_val = torch.tensor(real_u1(x_boundary, t_boundary, k, omega, r), device=device).float().view(-1, 1)\n",
    "    imag_u1_val = torch.tensor(imag_u1(x_boundary, t_boundary, k, omega, r), device=device).float().view(-1, 1)\n",
    "    real_v1_val = torch.tensor(real_v1(x_boundary, t_boundary, k, omega, r), device=device).float().view(-1, 1)\n",
    " \n",
    "    boundary_loss_ur = mse_cost_function(pred_u_r, real_u1_val)\n",
    "    boundary_loss_ui = mse_cost_function(pred_u_i, imag_u1_val)\n",
    "    boundary_loss_v = mse_cost_function(pred_v, real_v1_val)\n",
    "    \n",
    "    return boundary_loss_ur, boundary_loss_ui, boundary_loss_v\n",
    "\n",
    "def compute_physics_loss(model, x, t, mse_cost_function):\n",
    "    pred_u_r, pred_u_i, pred_v = model(x, t)\n",
    "\n",
    "    # Compute the differential equation residuals\n",
    "    du_eq_r, du_eq_i, dv_eq = coupled_higgs(pred_u_r, pred_u_i, pred_v, x, t)\n",
    "    \n",
    "    # Define target tensors of zeros with the same shape as the predictions\n",
    "    zeros_r = torch.zeros_like(du_eq_r, device=device)\n",
    "    zeros_i = torch.zeros_like(du_eq_i, device=device)\n",
    "    zeros_v = torch.zeros_like(dv_eq, device=device)\n",
    "    \n",
    "    # Compute the MSE loss against zeros for each differential equation residual\n",
    "    loss_r = mse_cost_function(du_eq_r, zeros_r)\n",
    "    loss_i = mse_cost_function(du_eq_i, zeros_i)\n",
    "    loss_v = mse_cost_function(dv_eq, zeros_v)\n",
    "    \n",
    "    # Return the scalar loss values for real part, imaginary part, and v\n",
    "    return loss_r, loss_i, loss_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db50cf9-4d8c-4166-8c14-ee7ec38a271b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Training on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   0%|\u001b[34m                                                  \u001b[0m|21:20:06\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss U (real): 1160.03173828125, Loss U (imag): 3703.409912109375, Loss V: 7313.49560546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   1%|\u001b[34m▌                                                 \u001b[0m|11:16:39\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000, Loss U (real): 31.595775604248047, Loss U (imag): 58.359954833984375, Loss V: 2.662620782852173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   2%|\u001b[34m█                                                 \u001b[0m|11:24:03\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2000, Loss U (real): 28.075519561767578, Loss U (imag): 54.76741027832031, Loss V: 10.06092643737793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   3%|\u001b[34m█▌                                                \u001b[0m|11:01:54\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3000, Loss U (real): 26.80469512939453, Loss U (imag): 54.42659378051758, Loss V: 3.4974169731140137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   4%|\u001b[34m██                                                \u001b[0m|10:59:23\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4000, Loss U (real): 26.366165161132812, Loss U (imag): 54.50551986694336, Loss V: 3.612208366394043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   5%|\u001b[34m██▌                                               \u001b[0m|10:52:02\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5000, Loss U (real): 26.581941604614258, Loss U (imag): 52.729515075683594, Loss V: 3.719754219055176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   6%|\u001b[34m███                                               \u001b[0m|10:46:21\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6000, Loss U (real): 25.967315673828125, Loss U (imag): 53.67302322387695, Loss V: 6.043526649475098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   7%|\u001b[34m███▌                                              \u001b[0m|10:48:41\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7000, Loss U (real): 25.69550895690918, Loss U (imag): 52.396942138671875, Loss V: 4.1868815422058105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   8%|\u001b[34m████                                              \u001b[0m|10:47:27\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8000, Loss U (real): 25.57976722717285, Loss U (imag): 54.84871292114258, Loss V: 9.71056079864502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   9%|\u001b[34m████▌                                             \u001b[0m|10:40:49\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9000, Loss U (real): 23.238574981689453, Loss U (imag): 52.988929748535156, Loss V: 6.095447540283203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::  10%|\u001b[34m█████                                             \u001b[0m|10:52:20\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10000, Loss U (real): 23.156105041503906, Loss U (imag): 51.401023864746094, Loss V: 6.026228904724121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::  11%|\u001b[34m█████▌                                            \u001b[0m|14:52:38\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11000, Loss U (real): 23.47681999206543, Loss U (imag): 51.096717834472656, Loss V: 5.296541690826416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::  12%|\u001b[34m██████                                            \u001b[0m|12:34:48\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12000, Loss U (real): 23.737773895263672, Loss U (imag): 50.93486022949219, Loss V: 4.377358436584473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::  12%|\u001b[34m██████                                            \u001b[0m|11:41:50\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and set the default device\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! Training on GPU.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Training on CPU.\")\n",
    "\n",
    "model = FourierFeatureNN(input_dim=1, shared_units=128, output_dim=3, layers_per_path=3, std_dev=1.0, activation=nn.Tanh, device=device).to(device)\n",
    "\n",
    "\n",
    "num_epochs = 100000  # Number of training epochs\n",
    "lr = 1e-3          # Learning rate\n",
    "num_samples = 1000 # Number of samples for training\n",
    "r = 1.1\n",
    "omega = 5\n",
    "k = 0.5\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "mse_cost_function = torch.nn.MSELoss()\n",
    "model_save_path = 'model_weights_testing_CHIGGS_fourier_collective'\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "losses = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs),\n",
    "                  desc='Progress:',  # Empty description\n",
    "                  leave=False,  # Do not leave the progress bar when done\n",
    "                  ncols=75,  # Width of the progress bar\n",
    "                  mininterval=0.1,\n",
    "                  bar_format='{l_bar}{bar}|{remaining}',  # Only show the bar without any counters\n",
    "                  colour='blue'):\n",
    "    x_n = (torch.rand(num_samples, 1) * 1).to(device)  # x in range [-5, -3]\n",
    "    t_n = (torch.rand(num_samples, 1) * 1).to(device)   \n",
    "    x_n.requires_grad = True\n",
    "    t_n.requires_grad = True\n",
    "    x_bc_x0 = np.zeros((num_samples, 1))\n",
    "    t_bc_x0 = np.random.uniform(0, 1, (num_samples, 1))\n",
    "    x_bc_x1 = np.ones((num_samples, 1))\n",
    "    t_bc_x1 = np.random.uniform(0, 1, (num_samples, 1))\n",
    "    x_bc_t0 = np.random.uniform(0, 1, (num_samples, 1))\n",
    "    t_bc_t0 = np.zeros((num_samples, 1))\n",
    "    x_bc_t1 = np.random.uniform(0, 1, (num_samples, 1))\n",
    "    t_bc_t1 = np.ones((num_samples, 1))\n",
    "    x_dom = np.random.uniform(0, 1, (num_samples, 1))\n",
    "    t_dom = np.random.uniform(0, 1, (num_samples, 1))\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    physics_loss_ur, physics_loss_ui, physics_loss_v = compute_physics_loss(model, x_n, t_n, mse_cost_function)\n",
    "    boundary_loss_ur_x0, boundary_loss_ui_x0, boundary_loss_v_x0 = compute_analytical_boundary_loss(model, x_bc_x0, t_bc_x0, mse_cost_function, k, omega, r)\n",
    "    boundary_loss_ur_x1, boundary_loss_ui_x1, boundary_loss_v_x1 = compute_analytical_boundary_loss(model, x_bc_x1, t_bc_x1, mse_cost_function, k, omega, r)\n",
    "    boundary_loss_ur_t0, boundary_loss_ui_t0, boundary_loss_v_t0 = compute_analytical_boundary_loss(model, x_bc_t0, t_bc_t0, mse_cost_function, k, omega, r)\n",
    "    boundary_loss_ur_t1, boundary_loss_ui_t1, boundary_loss_v_t1 = compute_analytical_boundary_loss(model, x_bc_t1, t_bc_t1, mse_cost_function, k, omega, r)\n",
    "\n",
    "    domain_loss_ur_t, domain_loss_ui_t, domain_loss_v_t = compute_analytical_boundary_loss(model, x_dom, t_dom, mse_cost_function, k, omega, r)\n",
    "   \n",
    "    # Total loss \n",
    "    loss_ur = physics_loss_ur + boundary_loss_ur_x0 + boundary_loss_ur_x1 + boundary_loss_ur_t0 + boundary_loss_ur_t1 + domain_loss_ur_t\n",
    "    loss_ui = physics_loss_ui + boundary_loss_ui_x0 + boundary_loss_ui_x1 + boundary_loss_ui_t0 + boundary_loss_ui_t1 + domain_loss_ui_t\n",
    "    loss_v = physics_loss_v + boundary_loss_v_x0 + boundary_loss_v_x1 + boundary_loss_v_t0 + boundary_loss_v_t1 + domain_loss_v_t\n",
    "\n",
    "    total_loss = loss_ur + loss_ui + loss_v\n",
    "    \n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Print loss every few epochs\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Epoch {epoch}, Loss U (real): {loss_ur.item()}, Loss U (imag): {loss_ui.item()}, Loss V: {loss_v.item()}')\n",
    "        model_filename = os.path.join(model_save_path, f'C_HIGGS_collective_epoch_{epoch}.pth')\n",
    "        torch.save(model.state_dict(), model_filename)\n",
    "        \n",
    "        df_losses = pd.DataFrame(losses)\n",
    "        csv_file_path = 'loss_data/C_HIGGS_fourier_training_collective_losses.csv'\n",
    "        df_losses.to_csv(csv_file_path, index=False)\n",
    "    \n",
    "    if total_loss.item() < 0.01:\n",
    "        print(f'Stopping early at epoch {epoch} due to reaching target loss.')\n",
    "        break\n",
    "    \n",
    "    losses.append({\n",
    "        'Epoch': epoch,\n",
    "        'Loss U (Real)': loss_ur.item(),\n",
    "        'Loss U (Imag)': loss_ui.item(),\n",
    "        'Loss V': loss_v.item(),\n",
    "        'Total Loss': total_loss.item(),\n",
    "        'Physics Loss': physics_loss_ur.item() + physics_loss_ui.item() + physics_loss_v.item(),\n",
    "        'Boundary Loss U(Real)': boundary_loss_ur_x0.item() + boundary_loss_ur_x1.item() + boundary_loss_ur_t0.item() + boundary_loss_ur_t1.item(),\n",
    "        'Boundary Loss U(Imag)': boundary_loss_ui_x0.item() + boundary_loss_ui_x1.item() + boundary_loss_ui_t0.item() + boundary_loss_ui_t1.item(),\n",
    "        'Boundary Loss V': boundary_loss_v_x0.item() + boundary_loss_v_x1.item() + boundary_loss_v_t0.item() + boundary_loss_v_t1.item(),\n",
    "        'Domain Loss': domain_loss_ui_t + domain_loss_ur_t + domain_loss_v_t\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41415efe-af94-4990-aae2-740568842f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Generate a grid of x and t values\n",
    "x = np.linspace(0, 1, 400)  # x values\n",
    "t = np.linspace(0, 1, 400)  # t values\n",
    "X, T = np.meshgrid(x, t)\n",
    "X_flat = X.reshape(-1, 1)  # Reshape to (160000, 1) instead of flattening to (160000,)\n",
    "T_flat = T.reshape(-1, 1)  # Reshape to (160000, 1)\n",
    "\n",
    "# Convert to torch tensors and prepare for the model\n",
    "X_tensor = torch.from_numpy(X_flat).float().to(device)\n",
    "T_tensor = torch.from_numpy(T_flat).float().to(device)\n",
    "\n",
    "# Convert to torch tensors and prepare for the model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming shared_model is defined and loaded with trained parameters\n",
    "model_state = torch.load(os.path.join(model_save_path, 'C_HIGGS_collective_epoch_99000.pth'), map_location=device)\n",
    "\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "\n",
    "# Get predictions from the trained models\n",
    "with torch.no_grad():\n",
    "    pred_u_r, pred_u_i, pred_v = model(X_tensor, T_tensor)\n",
    "\n",
    "    # Reshape predictions to match the grid shape for plotting\n",
    "    pred_u_r = pred_u_r.cpu().numpy().reshape(X.shape)\n",
    "    pred_u_i = pred_u_i.cpu().numpy().reshape(X.shape)\n",
    "    pred_v = pred_v.cpu().numpy().reshape(X.shape)\n",
    "\n",
    "# Calculate the analytical solutions\n",
    "real_u1_analytical = real_u1(X, T, k, omega, r)\n",
    "imag_u1_analytical = imag_u1(X, T, k, omega, r)\n",
    "real_v1_analytical = real_v1(X, T, k, omega, r)\n",
    "\n",
    "# Plotting\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "# Plot predicted and analytical real part of u1\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "surf1 = ax1.plot_surface(X, T, pred_u_r, cmap='viridis')\n",
    "fig.colorbar(surf1, ax=ax1, shrink=0.5, aspect=5)\n",
    "ax1.set_title('Predicted Real Part of $u_1(x, t)$')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('t')\n",
    "ax1.set_zlabel('Real part of $u_1$')\n",
    "\n",
    "# Plot predicted and analytical imaginary part of u1\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "surf2 = ax2.plot_surface(X, T, pred_u_i, cmap='viridis')\n",
    "fig.colorbar(surf2, ax=ax2, shrink=0.5, aspect=5)\n",
    "ax2.set_title('Predicted Imaginary Part of $u_1(x, t)$')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('t')\n",
    "ax2.set_zlabel('Imag part of $u_1$')\n",
    "\n",
    "# Plot predicted and analytical real part of v1\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "surf3 = ax3.plot_surface(X, T, pred_v, cmap='viridis')\n",
    "fig.colorbar(surf3, ax=ax3, shrink=0.5, aspect=5)\n",
    "ax3.set_title('Predicted Real Part of $v_1(x, t)$')\n",
    "ax3.set_xlabel('x')\n",
    "ax3.set_ylabel('t')\n",
    "ax3.set_zlabel('Real part of $v_1$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotting\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "# Plot predicted and analytical real part of u1\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "surf1 = ax1.plot_surface(X, T, real_u1_analytical, cmap='viridis')\n",
    "fig.colorbar(surf1, ax=ax1, shrink=0.5, aspect=5)\n",
    "ax1.set_title('Analytical Real Part of $u_1(x, t)$')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('t')\n",
    "ax1.set_zlabel('Real part of $u_1$')\n",
    "\n",
    "# Plot predicted and analytical imaginary part of u1\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "surf2 = ax2.plot_surface(X, T, imag_u1_analytical, cmap='viridis')\n",
    "fig.colorbar(surf2, ax=ax2, shrink=0.5, aspect=5)\n",
    "ax2.set_title('Analytical Imaginary Part of $u_1(x, t)$')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('t')\n",
    "ax2.set_zlabel('Imag part of $u_1$')\n",
    "\n",
    "# Plot predicted and analytical real part of v1\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "surf3 = ax3.plot_surface(X, T, real_v1_analytical, cmap='viridis')\n",
    "fig.colorbar(surf3, ax=ax3, shrink=0.5, aspect=5)\n",
    "ax3.set_title('Analytical Real Part of $v_1(x, t)$')\n",
    "ax3.set_xlabel('x')\n",
    "ax3.set_ylabel('t')\n",
    "ax3.set_zlabel('Real part of $v_1$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc963982-ee65-4af3-80c9-00804a8996d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
