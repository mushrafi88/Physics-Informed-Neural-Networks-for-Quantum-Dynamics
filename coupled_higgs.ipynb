{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc7a86c-65ae-45a3-97c5-67029d2b1726",
   "metadata": {},
   "source": [
    "# Coupled higgs equation \n",
    "$$\n",
    "u_{tt} - u_{xx} + |u|^2 u - 2uv = 0\n",
    "$$\n",
    "$$\n",
    "v_{tt} + v_{xx} - (\\left| u \\right|^2)_{xx} = 0\n",
    "$$\n",
    "\n",
    "where, $ u(x,t) $ represents a complex nucleon field and $ v(x,t) $ represents a real scalar meson field. The coupled Higgs field Equation describes a system of conserved scalar nucleon interaction with a neutral scalar meson.\n",
    "\n",
    "solutions \n",
    "\n",
    "$$\n",
    "u_1(x, t) = ir e^{ir(\\omega x + t)} \\sqrt{1 + \\omega^2} \\tanh\\left(\\frac{r(k + x + \\omega t)}{\\sqrt{2}}\\right)\n",
    "$$\n",
    "$$\n",
    "v_1(x, t) = r^2 \\tanh^2\\left(\\frac{r(k + x + \\omega t)}{\\sqrt{2}}\\right)\n",
    "$$\n",
    "\n",
    "for $t = 0$\n",
    "\n",
    "$$\n",
    "u_1(x, 0) = ir e^{ir \\omega x} \\sqrt{1 + \\omega^2} \\tanh\\left(\\frac{r(k + x)}{\\sqrt{2}}\\right)\n",
    "$$\n",
    "$$\n",
    "v_1(x, 0) = r^2 \\tanh^2\\left(\\frac{r(k + x)}{\\sqrt{2}}\\right)\n",
    "$$\n",
    "\n",
    "where \n",
    "$k = 4, \\omega = 5 , \\alpha = 2, c = 2, r = 2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ca80f90-4b39-47d4-92fa-5836d0bb6ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.anomaly_mode.set_detect_anomaly at 0x7fffd03f56a0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e75ae1ad-8395-460d-9320-69e19cf813bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourier_features(x, B):\n",
    "    x_transformed = torch.matmul(x, B)\n",
    "    return torch.cat([torch.sin(2 * torch.pi * x_transformed), torch.cos(2 * torch.pi * x_transformed)], dim=-1)\n",
    "\n",
    "def init_fixed_frequency_matrix(size, scale=1.0):\n",
    "    num_elements = size[0] * size[1]\n",
    "    lin_space = torch.linspace(-scale, scale, steps=num_elements)\n",
    "    B = lin_space.view(size).float()\n",
    "    return B\n",
    "\n",
    "class FourierFeatureNN(nn.Module):\n",
    "    def __init__(self, input_dim=1, shared_units=128, output_dim=1, layers_per_path=2, scale=1.0, activation=nn.Tanh, device = device):\n",
    "        super(FourierFeatureNN, self).__init__()\n",
    "        self.Bx = init_fixed_frequency_matrix((input_dim, shared_units // 2), scale=scale).to(device)\n",
    "        self.Bt = init_fixed_frequency_matrix((input_dim, shared_units // 2), scale=scale).to(device)\n",
    "    \n",
    "        # Define separate paths for x and t after Fourier transformation\n",
    "        self.path_x = nn.Sequential(\n",
    "            nn.Linear(shared_units, shared_units),  # Adjusted for Fourier features (sin and cos)\n",
    "            activation(),\n",
    "            *[layer for _ in range(layers_per_path - 1) for layer in (nn.Linear(shared_units, shared_units), activation())]\n",
    "        )\n",
    "\n",
    "        self.path_t = nn.Sequential(\n",
    "            nn.Linear(shared_units, shared_units),  # Adjusted for Fourier features\n",
    "            activation(),\n",
    "            *[layer for _ in range(layers_per_path - 1) for layer in (nn.Linear(shared_units, shared_units), activation())]\n",
    "        )\n",
    "\n",
    "        # Final layer after pointwise multiplication\n",
    "        self.final_layer = nn.Linear(shared_units, output_dim)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        # Apply Fourier feature transformations\n",
    "        x_fourier = fourier_features(x, self.Bx)\n",
    "        t_fourier = fourier_features(t, self.Bt)\n",
    "\n",
    "        # Pass through separate paths\n",
    "        x_path_output = self.path_x(x_fourier)\n",
    "        t_path_output = self.path_t(t_fourier)\n",
    "\n",
    "        # Pointwise multiplication of the separate path outputs\n",
    "        combined_features = x_path_output * t_path_output\n",
    "\n",
    "        # Final layer to produce output\n",
    "        final_output = self.final_layer(combined_features)\n",
    "        \n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f688fa-e181-425e-a818-c80ea518e9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(y, x):\n",
    "    return torch.autograd.grad(y, x, grad_outputs=torch.ones_like(y), create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "def laplacian(field, x, t):\n",
    "    field_x = grad(field, x)\n",
    "    field_xx = grad(field_x, x)\n",
    "    field_t = grad(field, t)\n",
    "    field_tt = grad(field_t, t)\n",
    "    return field_xx, field_tt\n",
    "\n",
    "# Define the ODE system for the Coupled Higgs field equations\n",
    "def coupled_higgs(u_real, u_imag, v, x, t):\n",
    "    u_r_xx, u_r_tt = laplacian(u_real, x, t)\n",
    "    u_i_xx, u_i_tt = laplacian(u_imag, x, t)\n",
    "    v_xx, v_tt = laplacian(v, x, t)\n",
    "\n",
    "    u_abs = torch.square(u_real) + torch.square(u_imag)\n",
    "    u_abs_xx, u_abs_tt = laplacian(u_abs, x, t)\n",
    "\n",
    "    # Calculate the field equations\n",
    "    du_eq_r = u_r_tt - u_r_xx + u_abs * u_real - 2 * u_real * v\n",
    "    du_eq_i = u_i_tt - u_i_xx + u_abs * u_imag - 2 * u_imag * v\n",
    "    dv_eq = v_tt + v_xx - u_abs_xx\n",
    "    \n",
    "    return du_eq_r, du_eq_i, dv_eq\n",
    "\n",
    "# Function to calculate the real part of u1\n",
    "# Function to calculate the real part of u1\n",
    "def real_u1(x, t, k, omega, r):\n",
    "    complex_exp = torch.exp(1j * r * (omega * x + t))\n",
    "    tanh_val = torch.tanh((r * (k + x + omega * t)) / torch.sqrt(torch.tensor(2.0)))\n",
    "    result = torch.real(1j * r * complex_exp * torch.sqrt(torch.tensor(1) + omega**2) * tanh_val)\n",
    "    return result\n",
    "\n",
    "def imag_u1(x, t, k, omega, r):\n",
    "    complex_exp = torch.exp(1j * r * (omega * x + t))\n",
    "    tanh_val = torch.tanh((r * (k + x + omega * t)) / torch.sqrt(torch.tensor(2.0)))\n",
    "    result = torch.imag(1j * r * complex_exp * torch.sqrt(torch.tensor(1) + omega**2) * tanh_val)\n",
    "    return result\n",
    "\n",
    "def real_v1(x, t, k, omega, r):\n",
    "    result = (r * torch.tanh((r * (k + x + omega * t)) / torch.sqrt(torch.tensor(2.0))))**2\n",
    "    return result\n",
    "\n",
    "def compute_analytical_boundary_loss(model_u1_real, model_u1_imag, model_v1, x_boundary, t_boundary, mse_cost_function, k, omega, r):\n",
    "    pred_u_r = model_u1_real(x_boundary, t_boundary)\n",
    "    pred_u_i = model_u1_imag(x_boundary, t_boundary)\n",
    "    pred_v = model_v1(x_boundary, t_boundary)\n",
    "\n",
    "    real_u1_val = real_u1(x_boundary, t_boundary, k, omega, r)\n",
    "    imag_u1_val = imag_u1(x_boundary, t_boundary, k, omega, r)\n",
    "    real_v1_val = real_v1(x_boundary, t_boundary, k, omega, r)\n",
    " \n",
    "    boundary_loss_ur = mse_cost_function(pred_u_r, real_u1_val)\n",
    "    boundary_loss_ui = mse_cost_function(pred_u_i, imag_u1_val)\n",
    "    boundary_loss_v = mse_cost_function(pred_v, real_v1_val)\n",
    "    \n",
    "    return boundary_loss_ur, boundary_loss_ui, boundary_loss_v\n",
    "\n",
    "def compute_physics_loss(model_u1_real, model_u1_imag, model_v1, x, t, mse_cost_function):\n",
    "    x.requires_grad = True\n",
    "    t.requires_grad = True\n",
    "    pred_u_r = model_u1_real(x, t)\n",
    "    pred_u_i = model_u1_imag(x, t)\n",
    "    pred_v = model_v1(x, t)\n",
    "\n",
    "    # Compute the differential equation residuals\n",
    "    du_eq_r, du_eq_i, dv_eq = coupled_higgs(pred_u_r, pred_u_i, pred_v, x, t)\n",
    "    \n",
    "    # Define target tensors of zeros with the same shape as the predictions\n",
    "    zeros_r = torch.zeros_like(du_eq_r, device=device)\n",
    "    zeros_i = torch.zeros_like(du_eq_i, device=device)\n",
    "    zeros_v = torch.zeros_like(dv_eq, device=device)\n",
    "    \n",
    "    # Compute the MSE loss against zeros for each differential equation residual\n",
    "    loss_r = mse_cost_function(du_eq_r, zeros_r)\n",
    "    loss_i = mse_cost_function(du_eq_i, zeros_i)\n",
    "    loss_v = mse_cost_function(dv_eq, zeros_v)\n",
    "    \n",
    "    # Return the scalar loss values for real part, imaginary part, and v\n",
    "    return loss_r, loss_i, loss_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f296d60-7405-4b4f-94c4-dc812c5a0d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Training on GPU.\n",
      "\n",
      "##################### model u1 real #################\n",
      "\n",
      "FourierFeatureNN(\n",
      "  (path_x): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): Tanh()\n",
      "  )\n",
      "  (path_t): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): Tanh()\n",
      "  )\n",
      "  (final_layer): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "##################### model u1 imag #################\n",
      "\n",
      "FourierFeatureNN(\n",
      "  (path_x): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): Tanh()\n",
      "  )\n",
      "  (path_t): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): Tanh()\n",
      "  )\n",
      "  (final_layer): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n",
      "\n",
      "##################### model v1 #################\n",
      "\n",
      "FourierFeatureNN(\n",
      "  (path_x): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): Tanh()\n",
      "  )\n",
      "  (path_t): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (3): Tanh()\n",
      "  )\n",
      "  (final_layer): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and set the default device\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! Training on GPU.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Training on CPU.\")\n",
    "\n",
    "model_u1_real = FourierFeatureNN(input_dim=1, shared_units=128, output_dim=1, layers_per_path=2, scale=1.0, activation=nn.Tanh).to(device)\n",
    "model_u1_imag = FourierFeatureNN(input_dim=1, shared_units=128, output_dim=1, layers_per_path=2, scale=1.0, activation=nn.Tanh).to(device)\n",
    "model_v1 = FourierFeatureNN(input_dim=1, shared_units=128, output_dim=1, layers_per_path=2, scale=1.0, activation=nn.Tanh).to(device)\n",
    "\n",
    "num_epochs = 100000  # Number of training epochs\n",
    "lr = 1e-3          # Learning rate\n",
    "num_samples = 1000 # Number of samples for training\n",
    "r = 1.1\n",
    "omega = 5\n",
    "k = 0.5\n",
    "lambda_ = 1e-3\n",
    "\n",
    "optimizer_u1_real = Adam(model_u1_real.parameters(), lr=lr)\n",
    "optimizer_u1_imag = Adam(model_u1_imag.parameters(), lr=lr)\n",
    "optimizer_v1 = Adam(model_v1.parameters(), lr=lr)\n",
    "mse_cost_function = torch.nn.MSELoss()\n",
    "model_save_path = 'model_weights_testing_CHIGGS_fourier'\n",
    "os.makedirs(model_save_path, exist_ok=True)\n",
    "losses = []\n",
    "\n",
    "print('\\n##################### model u1 real #################\\n')\n",
    "print(model_u1_real)\n",
    "print('\\n##################### model u1 imag #################\\n')\n",
    "print(model_u1_imag)\n",
    "print('\\n##################### model v1 #################\\n')\n",
    "print(model_v1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20e63fa-c163-4640-a4db-118769e1e2f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   0%|\u001b[34m                                                  \u001b[0m|18:11:11\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss U (real): 37.26082229614258, Loss U (imag): 64.36723327636719, Loss V: 4.143613338470459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   1%|\u001b[34m▌                                                 \u001b[0m|11:01:10\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000, Loss U (real): 1.4625951051712036, Loss U (imag): 1.2322988510131836, Loss V: 0.3142704665660858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   2%|\u001b[34m█                                                 \u001b[0m|11:02:52\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2000, Loss U (real): 1.2734436988830566, Loss U (imag): 0.9071477651596069, Loss V: 0.7139945030212402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   2%|\u001b[34m█                                                 \u001b[0m|11:31:53\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs),\n",
    "                  desc='Progress:',  # Empty description\n",
    "                  leave=False,  # Do not leave the progress bar when done\n",
    "                  ncols=75,  # Width of the progress bar\n",
    "                  mininterval=0.1,\n",
    "                  bar_format='{l_bar}{bar}|{remaining}',  # Only show the bar without any counters\n",
    "                  colour='blue'): \n",
    "    x_n = (torch.rand(num_samples, 1)).to(device)  # x in range [-5, -3]\n",
    "    t_n = (torch.rand(num_samples, 1)).to(device)   \n",
    "    x_bc_x0 = torch.zeros((num_samples, 1)).to(device)\n",
    "    t_bc_x0 = torch.rand((num_samples, 1)).to(device)  # Uniformly distributed random values between 0 and 1\n",
    "    x_bc_x1 = torch.ones((num_samples, 1)).to(device)\n",
    "    t_bc_x1 = torch.rand((num_samples, 1)).to(device)  # Uniformly distributed random values between 0 and 1\n",
    "    x_bc_t0 = torch.rand((num_samples, 1)).to(device)  # Uniformly distributed random values between 0 and 1\n",
    "    t_bc_t0 = torch.zeros((num_samples, 1)).to(device)\n",
    "    x_bc_t1 = torch.rand((num_samples, 1)).to(device)  # Uniformly distributed random values between 0 and 1\n",
    "    t_bc_t1 = torch.ones((num_samples, 1)).to(device)\n",
    "    x_dom = torch.rand((num_samples, 1)).to(device)\n",
    "    t_dom = torch.rand((num_samples, 1)).to(device)\n",
    "    \n",
    "    optimizer_u1_real.zero_grad()\n",
    "    optimizer_u1_imag.zero_grad()\n",
    "    optimizer_v1.zero_grad()\n",
    "\n",
    "    physics_loss_ur, physics_loss_ui, physics_loss_v = compute_physics_loss(model_u1_real, model_u1_imag, model_v1, x_n, t_n, mse_cost_function)\n",
    "    boundary_loss_ur_x0, boundary_loss_ui_x0, boundary_loss_v_x0 = compute_analytical_boundary_loss(model_u1_real, model_u1_imag, model_v1, x_bc_x0, t_bc_x0, mse_cost_function, k, omega, r)\n",
    "    boundary_loss_ur_x1, boundary_loss_ui_x1, boundary_loss_v_x1 = compute_analytical_boundary_loss(model_u1_real, model_u1_imag, model_v1, x_bc_x1, t_bc_x1, mse_cost_function, k, omega, r)\n",
    "    boundary_loss_ur_t0, boundary_loss_ui_t0, boundary_loss_v_t0 = compute_analytical_boundary_loss(model_u1_real, model_u1_imag, model_v1, x_bc_t0, t_bc_t0, mse_cost_function, k, omega, r)\n",
    "    boundary_loss_ur_t1, boundary_loss_ui_t1, boundary_loss_v_t1 = compute_analytical_boundary_loss(model_u1_real, model_u1_imag, model_v1, x_bc_t1, t_bc_t1, mse_cost_function, k, omega, r)\n",
    "\n",
    "    domain_loss_ur_t, domain_loss_ui_t, domain_loss_v_t = compute_analytical_boundary_loss(model_u1_real, model_u1_imag, model_v1, x_dom, t_dom, mse_cost_function, k, omega, r)\n",
    "   \n",
    "    # Total loss \n",
    "    loss_ur = lambda_*(physics_loss_ur + domain_loss_ur_t) + (1-lambda_)*(boundary_loss_ur_x0 + boundary_loss_ur_x1 + boundary_loss_ur_t0 + boundary_loss_ur_t1)\n",
    "    loss_ui = lambda_*(physics_loss_ui + domain_loss_ui_t) + (1-lambda_)*(boundary_loss_ui_x0 + boundary_loss_ui_x1 + boundary_loss_ui_t0 + boundary_loss_ui_t1)\n",
    "    loss_v = lambda_*(physics_loss_v + domain_loss_v_t) + (1-lambda_)*(boundary_loss_v_x0 + boundary_loss_v_x1 + boundary_loss_v_t0 + boundary_loss_v_t1)\n",
    "\n",
    "    total_loss = loss_ur + loss_ui + loss_v\n",
    "    \n",
    "    total_loss.backward()\n",
    "    optimizer_u1_real.step()\n",
    "    optimizer_u1_imag.step()\n",
    "    optimizer_v1.step()\n",
    "    \n",
    "    # Print loss every few epochs\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Epoch {epoch}, Loss U (real): {loss_ur.item()}, Loss U (imag): {loss_ui.item()}, Loss V: {loss_v.item()}')\n",
    "        model_u1_real_filename = os.path.join(model_save_path, f'C_HIGGS_U1_real_epoch_{epoch}.pth')\n",
    "        torch.save(model_u1_real.state_dict(), model_u1_real_filename)\n",
    "\n",
    "        model_u1_imag_filename = os.path.join(model_save_path, f'C_HIGGS_U1_imag_epoch_{epoch}.pth')\n",
    "        torch.save(model_u1_imag.state_dict(), model_u1_imag_filename)\n",
    "        \n",
    "        model_v1_filename = os.path.join(model_save_path, f'C_HIGGS_V1_epoch_{epoch}.pth')\n",
    "        torch.save(model_v1.state_dict(), model_v1_filename)\n",
    "        \n",
    "        df_losses = pd.DataFrame(losses)\n",
    "        csv_file_path = 'loss_data/C_HIGGS_fourier_training_losses.csv'\n",
    "        df_losses.to_csv(csv_file_path, index=False)\n",
    "    \n",
    "    if total_loss.item() < 1e-3:\n",
    "        print(f'Stopping early at epoch {epoch} due to reaching target loss.')\n",
    "        model_u1_real_filename = os.path.join(model_save_path, f'C_HIGGS_U1_real_epoch_{epoch}.pth')\n",
    "        torch.save(model_u1_real.state_dict(), model_u1_real_filename)\n",
    "\n",
    "        model_u1_imag_filename = os.path.join(model_save_path, f'C_HIGGS_U1_imag_epoch_{epoch}.pth')\n",
    "        torch.save(model_u1_imag.state_dict(), model_u1_imag_filename)\n",
    "        \n",
    "        model_v1_filename = os.path.join(model_save_path, f'C_HIGGS_V1_epoch_{epoch}.pth')\n",
    "        torch.save(model_v1.state_dict(), model_v1_filename)\n",
    "        break\n",
    "    \n",
    "    losses.append({\n",
    "        'Epoch': epoch,\n",
    "        'Loss U (Real)': loss_ur.item(),\n",
    "        'Loss U (Imag)': loss_ui.item(),\n",
    "        'Loss V': loss_v.item(),\n",
    "        'Total Loss': total_loss.item(),\n",
    "        'Physics Loss': physics_loss_ur.item() + physics_loss_ui.item() + physics_loss_v.item(),\n",
    "        'Boundary Loss U(Real)': boundary_loss_ur_x0.item() + boundary_loss_ur_x1.item() + boundary_loss_ur_t0.item() + boundary_loss_ur_t1.item(),\n",
    "        'Boundary Loss U(Imag)': boundary_loss_ui_x0.item() + boundary_loss_ui_x1.item() + boundary_loss_ui_t0.item() + boundary_loss_ui_t1.item(),\n",
    "        'Boundary Loss V': boundary_loss_v_x0.item() + boundary_loss_v_x1.item() + boundary_loss_v_t0.item() + boundary_loss_v_t1.item(),\n",
    "        'Domain Loss': domain_loss_ui_t + domain_loss_ur_t + domain_loss_v_t\n",
    "    })\n",
    "\n",
    "df_losses = pd.DataFrame(losses)\n",
    "csv_file_path = 'loss_data/C_HIGGS_training_losses.csv'\n",
    "df_losses.to_csv(csv_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af66534-7097-4f70-a124-5dd14d593cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "x = torch.linspace(0, 1, 400)\n",
    "t = torch.linspace(0, 1, 400)\n",
    "X, T = torch.meshgrid(x, t)  # Create a 2D grid of x and t\n",
    "X_flat = X.flatten().unsqueeze(-1).to(device)\n",
    "T_flat = T.flatten().unsqueeze(-1).to(device)\n",
    "\n",
    "# Assuming shared_model is defined and loaded with trained parameters\n",
    "model_u1_real_state = torch.load(os.path.join(model_save_path, f'C_HIGGS_U1_real_epoch_{epoch}.pth'), map_location=device)\n",
    "model_u1_imag_state = torch.load(os.path.join(model_save_path, f'C_HIGGS_U1_imag_epoch_{epoch}.pth'), map_location=device)\n",
    "model_v1_state = torch.load(os.path.join(model_save_path, f'C_HIGGS_V1_epoch_{epoch}.pth'), map_location=device)\n",
    "model_u1_real = FourierFeatureNN(input_dim=1, shared_units=128, output_dim=1, layers_per_path=2, scale=1.0, activation=nn.Tanh).to(device)\n",
    "model_u1_imag = FourierFeatureNN(input_dim=1, shared_units=128, output_dim=1, layers_per_path=2, scale=1.0, activation=nn.Tanh).to(device)\n",
    "model_v1 = FourierFeatureNN(input_dim=1, shared_units=128, output_dim=1, layers_per_path=2, scale=1.0, activation=nn.Tanh).to(device)\n",
    "model_u1_real.load_state_dict(model_u1_real_state)\n",
    "model_u1_imag.load_state_dict(model_u1_imag_state)\n",
    "model_v1.load_state_dict(model_v1_state)\n",
    "model_u1_real.eval()\n",
    "model_u1_imag.eval()\n",
    "model_v1.eval()\n",
    "# Get predictions from the trained models\n",
    "with torch.no_grad():\n",
    "    pred_u_r = model_u1_real(X_flat, T_flat).cpu().reshape(X.shape).numpy()\n",
    "    pred_u_i = model_u1_imag(X_flat, T_flat).cpu().reshape(X.shape).numpy()\n",
    "    pred_v = model_v1(X_flat, T_flat).cpu().reshape(X.shape).numpy()\n",
    "\n",
    "real_u1_analytical = real_u1(X_flat, T_flat, k, omega, r).cpu().reshape(X.shape).numpy()\n",
    "imag_u1_analytical = imag_u1(X_flat, T_flat, k, omega, r).cpu().reshape(X.shape).numpy()\n",
    "real_v1_analytical = real_v1(X_flat, T_flat, k, omega, r).cpu().reshape(X.shape).numpy()\n",
    "\n",
    "# Plotting predictions\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "# Plot predicted real part of u1\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "surf1 = ax1.plot_surface(X.numpy(), T.numpy(), pred_u_r, cmap='viridis')\n",
    "fig.colorbar(surf1, ax=ax1, shrink=0.5, aspect=5)\n",
    "ax1.set_title('Predicted Real Part of $u_1(x, t)$')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('t')\n",
    "ax1.set_zlabel('Real part of $u_1$')\n",
    "\n",
    "# Plot predicted imaginary part of u1\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "surf2 = ax2.plot_surface(X.numpy(), T.numpy(), pred_u_i, cmap='viridis')\n",
    "fig.colorbar(surf2, ax=ax2, shrink=0.5, aspect=5)\n",
    "ax2.set_title('Predicted Imaginary Part of $u_1(x, t)$')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('t')\n",
    "ax2.set_zlabel('Imag part of $u_1$')\n",
    "\n",
    "# Plot predicted real part of v1\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "surf3 = ax3.plot_surface(X.numpy(), T.numpy(), pred_v, cmap='viridis')\n",
    "fig.colorbar(surf3, ax=ax3, shrink=0.5, aspect=5)\n",
    "ax3.set_title('Predicted Real Part of $v_1(x, t)$')\n",
    "ax3.set_xlabel('x')\n",
    "ax3.set_ylabel('t')\n",
    "ax3.set_zlabel('Real part of $v_1$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plotting analytical solutions\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "\n",
    "# Plot analytical real part of u1\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "surf1 = ax1.plot_surface(X.numpy(), T.numpy(), real_u1_analytical, cmap='viridis')\n",
    "fig.colorbar(surf1, ax=ax1, shrink=0.5, aspect=5)\n",
    "ax1.set_title('Analytical Real Part of $u_1(x, t)$')\n",
    "ax1.set_xlabel('x')\n",
    "ax1.set_ylabel('t')\n",
    "ax1.set_zlabel('Real part of $u_1$')\n",
    "\n",
    "# Plot analytical imaginary part of u1\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "surf2 = ax2.plot_surface(X.numpy(), T.numpy(), imag_u1_analytical, cmap='viridis')\n",
    "fig.colorbar(surf2, ax=ax2, shrink=0.5, aspect=5)\n",
    "ax2.set_title('Analytical Imaginary Part of $u_1(x, t)$')\n",
    "ax2.set_xlabel('x')\n",
    "ax2.set_ylabel('t')\n",
    "ax2.set_zlabel('Imag part of $u_1$')\n",
    "\n",
    "# Plot analytical real part of v1\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "surf3 = ax3.plot_surface(X.numpy(), T.numpy(), real_v1_analytical, cmap='viridis')\n",
    "fig.colorbar(surf3, ax=ax3, shrink=0.5, aspect=5)\n",
    "ax3.set_title('Analytical Real Part of $v_1(x, t)$')\n",
    "ax3.set_xlabel('x')\n",
    "ax3.set_ylabel('t')\n",
    "ax3.set_zlabel('Real part of $v_1$')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc963982-ee65-4af3-80c9-00804a8996d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
