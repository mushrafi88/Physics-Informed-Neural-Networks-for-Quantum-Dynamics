{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc7a86c-65ae-45a3-97c5-67029d2b1726",
   "metadata": {},
   "source": [
    "# Coupled higgs equation \n",
    "$$\n",
    "u_{tt} - u_{xx} + |u|^2 u - 2uv = 0\n",
    "$$\n",
    "$$\n",
    "v_{tt} + v_{xx} - (\\left| u \\right|^2)_{xx} = 0\n",
    "$$\n",
    "\n",
    "where, $ u(x,t) $ represents a complex nucleon field and $ v(x,t) $ represents a real scalar meson field. The coupled Higgs field Equation describes a system of conserved scalar nucleon interaction with a neutral scalar meson.\n",
    "\n",
    "solutions \n",
    "\n",
    "$$\n",
    "u_1(x, t) = ir e^{ir(\\omega x + t)} \\sqrt{1 + \\omega^2} \\tanh\\left(\\frac{r(k + x + \\omega t)}{\\sqrt{2}}\\right)\n",
    "$$\n",
    "$$\n",
    "v_1(x, t) = r^2 \\tanh^2\\left(\\frac{r(k + x + \\omega t)}{\\sqrt{2}}\\right)\n",
    "$$\n",
    "\n",
    "for $t = 0$\n",
    "\n",
    "$$\n",
    "u_1(x, 0) = ir e^{ir \\omega x} \\sqrt{1 + \\omega^2} \\tanh\\left(\\frac{r(k + x)}{\\sqrt{2}}\\right)\n",
    "$$\n",
    "$$\n",
    "v_1(x, 0) = r^2 \\tanh^2\\left(\\frac{r(k + x)}{\\sqrt{2}}\\right)\n",
    "$$\n",
    "\n",
    "where \n",
    "$k = 4, \\omega = 5 , \\alpha = 2, c = 2, r = 2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab48d2a8-7aee-4e3e-a73e-fb43bf687d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')\n",
    "\n",
    "class SinActv(nn.Module):\n",
    "    def forward(self, input_):\n",
    "        return torch.sin(input_)\n",
    "\n",
    "class ModelU1(nn.Module):\n",
    "    def __init__(self, n_input_units=2, shared_units=128, branch_units=32, n_output_units=1, n_shared_layers=4, n_branch_layers=1, actv=nn.Tanh):\n",
    "        super(ModelU1, self).__init__()\n",
    "        # Initial shared layers setup\n",
    "        self.shared_layers = nn.ModuleList()\n",
    "        for i in range(n_shared_layers):\n",
    "            if i == 0:\n",
    "                self.shared_layers.append(nn.Linear(n_input_units, shared_units))\n",
    "            else:\n",
    "                self.shared_layers.append(nn.Linear(shared_units, shared_units))\n",
    "            self.shared_layers.append(actv())\n",
    "\n",
    "        # Branch for u_real\n",
    "        self.branch_u_r_layers = self._make_branch_layers(shared_units, branch_units, n_output_units, n_branch_layers, actv)\n",
    "\n",
    "        # Branch for u_imag\n",
    "        self.branch_u_i_layers = self._make_branch_layers(shared_units, branch_units, n_output_units, n_branch_layers, actv)\n",
    "\n",
    "    def _make_branch_layers(self, in_units, units_per_layer, n_output_units, n_layers, actv):\n",
    "        layers = nn.ModuleList()\n",
    "        for i in range(n_layers):\n",
    "            layers.append(nn.Linear(in_units, units_per_layer))\n",
    "            layers.append(actv())\n",
    "            in_units = units_per_layer\n",
    "        layers.append(nn.Linear(in_units, n_output_units))\n",
    "        return layers\n",
    "\n",
    "    def _forward_branch(self, shared, layers):\n",
    "        x = shared\n",
    "        for layer in layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared = x\n",
    "        for layer in self.shared_layers:\n",
    "            shared = layer(shared)\n",
    "        u_r = self._forward_branch(shared, self.branch_u_r_layers)\n",
    "        u_i = self._forward_branch(shared, self.branch_u_i_layers)\n",
    "        return u_r, u_i\n",
    "\n",
    "class ModelV1(nn.Module):\n",
    "    def __init__(self, n_input_units=2, shared_units=128, n_output_units=1, n_layers=5, actv=nn.Tanh):\n",
    "        super(ModelV1, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for i in range(n_layers):\n",
    "            if i == 0:\n",
    "                self.layers.append(nn.Linear(n_input_units, shared_units))\n",
    "            else:\n",
    "                self.layers.append(nn.Linear(shared_units, shared_units))\n",
    "            self.layers.append(actv())\n",
    "        # Output layer for v\n",
    "        self.layers.append(nn.Linear(shared_units, n_output_units))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "def grad(outputs, inputs):\n",
    "    return torch.autograd.grad(outputs, inputs, grad_outputs=torch.ones_like(outputs), create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "def laplacian(field, x, t):\n",
    "    field_x = grad(field, x)\n",
    "    field_xx = grad(field_x, x)\n",
    "    field_t = grad(field, t)\n",
    "    field_tt = grad(field_t, t)\n",
    "    return field_xx, field_tt\n",
    "\n",
    "# Define the ODE system for the Coupled Higgs field equations\n",
    "def coupled_higgs(u_real, u_imag, v, x, t):\n",
    "    u_r_xx, u_r_tt = laplacian(u_real, x, t)\n",
    "    u_i_xx, u_i_tt = laplacian(u_imag, x, t)\n",
    "    v_xx, v_tt = laplacian(v, x, t)\n",
    "\n",
    "    u_abs = u_real**2 + u_imag**2\n",
    "    u_abs_xx, u_abs_tt = laplacian(u_abs, x, t)\n",
    "\n",
    "    # Calculate the field equations\n",
    "    du_eq_r = u_r_tt - u_r_xx + u_abs * u_real - 2 * u_real * v\n",
    "    du_eq_i = u_i_tt - u_i_xx + u_abs * u_imag - 2 * u_imag * v\n",
    "    dv_eq = v_tt + v_xx - u_abs_xx\n",
    "    \n",
    "    return du_eq_r, du_eq_i, dv_eq\n",
    "\n",
    "# Function to calculate the real part of u1\n",
    "def real_u1(x, t, k, omega, r):\n",
    "    return np.real(1j * r * np.exp(1j * r * (omega * x + t)) * np.sqrt(1 + omega**2) *\n",
    "                   np.tanh((r * (k + x + omega * t)) / np.sqrt(2)))\n",
    "\n",
    "def imag_u1(x, t, k, omega, r):\n",
    "    return np.imag(1j * r * np.exp(1j * r * (omega * x + t)) * np.sqrt(1 + omega**2) *\n",
    "                   np.tanh((r * (k + x + omega * t)) / np.sqrt(2)))\n",
    "    \n",
    "def real_v1(x, t, k, omega, r):\n",
    "    return (r * np.tanh((r * (k + x + omega * t)) / np.sqrt(2)) )**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb126df9-aa1b-4091-b074-cb7a5128a9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and set the default device\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! Training on GPU.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Training on CPU.\")\n",
    "\n",
    "model_u1 = ModelU1(n_input_units=2, shared_units=128, branch_units=32, n_output_units=1, n_shared_layers=4, n_branch_layers=1, actv=nn.Tanh).to(device)\n",
    "model_v1 = ModelV1(n_input_units=2, shared_units=128, n_output_units=1, n_layers=5, actv=nn.Tanh).to(device)\n",
    "\n",
    "num_epochs = 100000  # Number of training epochs\n",
    "lr = 1e-3          # Learning rate\n",
    "num_samples = 1000 # Number of samples for training\n",
    "k = 4\n",
    "omega = 5\n",
    "r = 2\n",
    "\n",
    "optimizer_u1 = Adam(model_u1.parameters(), lr=lr)\n",
    "optimizer_v1 = Adam(model_v1.parameters(), lr=lr)\n",
    "mse_cost_function = torch.nn.MSELoss()\n",
    "model_save_path = 'model_weights'\n",
    "os.makedirs(model_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0758e6d7-76b1-428e-a8fc-c5f4c065f22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Training on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   0%|                      | 3/100000 [00:00<2:30:55, 11.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss U: 308.2165222167969 , Loss V: 39.47106170654297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   0%|                     | 72/100000 [00:04<1:37:54, 17.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 151\u001b[0m\n\u001b[1;32m    149\u001b[0m pred_v \u001b[38;5;241m=\u001b[39m model_v1(x_t)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m#pred_u_r, pred_u_i, pred_v = shared_model(x_t)\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m du_eq_r, du_eq_i, dv_eq \u001b[38;5;241m=\u001b[39m \u001b[43mcoupled_higgs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_u_r\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_u_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred_v\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m loss_pde_u \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(du_eq_r\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m du_eq_i\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Loss for U1 model components\u001b[39;00m\n\u001b[1;32m    153\u001b[0m loss_pde_v \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(dv_eq\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# Loss for V1 model component\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 89\u001b[0m, in \u001b[0;36mcoupled_higgs\u001b[0;34m(u_real, u_imag, v, x, t)\u001b[0m\n\u001b[1;32m     87\u001b[0m u_r_xx, u_r_tt \u001b[38;5;241m=\u001b[39m laplacian(u_real, x, t)\n\u001b[1;32m     88\u001b[0m u_i_xx, u_i_tt \u001b[38;5;241m=\u001b[39m laplacian(u_imag, x, t)\n\u001b[0;32m---> 89\u001b[0m v_xx, v_tt \u001b[38;5;241m=\u001b[39m \u001b[43mlaplacian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     91\u001b[0m u_abs \u001b[38;5;241m=\u001b[39m u_real\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m u_imag\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     92\u001b[0m u_abs_xx, u_abs_tt \u001b[38;5;241m=\u001b[39m laplacian(u_abs, x, t)\n",
      "Cell \u001b[0;32mIn[4], line 82\u001b[0m, in \u001b[0;36mlaplacian\u001b[0;34m(field, x, t)\u001b[0m\n\u001b[1;32m     80\u001b[0m field_xx \u001b[38;5;241m=\u001b[39m grad(field_x, x)\n\u001b[1;32m     81\u001b[0m field_t \u001b[38;5;241m=\u001b[39m grad(field, t)\n\u001b[0;32m---> 82\u001b[0m field_tt \u001b[38;5;241m=\u001b[39m \u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m field_xx, field_tt\n",
      "Cell \u001b[0;32mIn[4], line 76\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgrad\u001b[39m(outputs, inputs):\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Physics-Informed-Neural-Networks-for-Quantum-Dynamics/.mamba/envs/pytorch/lib/python3.12/site-packages/torch/autograd/__init__.py:411\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched, materialize_grads)\u001b[0m\n\u001b[1;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(\n\u001b[1;32m    408\u001b[0m         grad_outputs_\n\u001b[1;32m    409\u001b[0m     )\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 411\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    418\u001b[0m \u001b[43m        \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m materialize_grads:\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\n\u001b[1;32m    422\u001b[0m         result[i] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tensor_like(inputs[i])\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(inputs))\n\u001b[1;32m    424\u001b[0m     ):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs),desc='Progress:', leave=True, ncols=75, mininterval=0.1, ascii=False):\n",
    "    # Generate random samples for x and t\n",
    "    x = (torch.rand(num_samples, 1) * 2 - 5).to(device)  # x in range [-5, -3]\n",
    "    x.requires_grad = True\n",
    "    t = (torch.rand(num_samples, 1) * 1).to(device)      # t in range [0, 1]\n",
    "    t.requires_grad = True\n",
    "    x_t = torch.cat([x, t], dim=1) \n",
    "    \n",
    "    optimizer_u1.zero_grad()\n",
    "    pred_u_r, pred_u_i = model_u1(x_t)\n",
    "    optimizer_v1.zero_grad()\n",
    "    pred_v = model_v1(x_t)\n",
    "    #pred_u_r, pred_u_i, pred_v = shared_model(x_t)\n",
    "    du_eq_r, du_eq_i, dv_eq = coupled_higgs(pred_u_r, pred_u_i, pred_v, x, t)\n",
    "    loss_pde_u = torch.mean(du_eq_r**2 + du_eq_i**2)  # Loss for U1 model components\n",
    "    loss_pde_v = torch.mean(dv_eq**2)  # Loss for V1 model component\n",
    "\n",
    "    # Calculate the boundary loss at t=0\n",
    "    x_bc = np.random.uniform(-5, -3, (num_samples, 1))\n",
    "    t_bc = np.zeros((num_samples, 1))\n",
    "    real_u1_t0_val = torch.tensor(real_u1(x_bc, t_bc, k, omega, r), device=device).float().view(-1, 1)\n",
    "    imag_u1_t0_val = torch.tensor(imag_u1(x_bc, t_bc, k, omega, r), device=device).float().view(-1, 1)\n",
    "    real_v1_t0_val = torch.tensor(real_v1(x_bc, t_bc, k, omega, r), device=device).float().view(-1, 1)\n",
    "    x_t0 = Variable(torch.from_numpy(np.hstack([x_bc, t_bc])).float(), requires_grad=False).to(device)\n",
    "    #pred_u_r0, pred_u_i0, pred_v0 = shared_model(x_t0)\n",
    "    pred_u_r0, pred_u_i0 = model_u1(x_t0) \n",
    "    pred_v0 = model_v1(x_t0)\n",
    "    boundary_loss_ur0 = mse_cost_function(pred_u_r0, real_u1_t0_val)\n",
    "    boundary_loss_ui0 = mse_cost_function(pred_u_i0, imag_u1_t0_val)\n",
    "    \n",
    "    boundary_loss_v_t0 = mse_cost_function(pred_v0, real_v1_t0_val)\n",
    "    boundary_loss_u_t0 = torch.mean(boundary_loss_ur0 + boundary_loss_ui0)\n",
    "    # boundary cond for x = -5 and x = -3 \n",
    "\n",
    "    # Calculate the boundary loss at x = -5\n",
    "    t_bc_5 = np.random.uniform(0, 1, (num_samples, 1))\n",
    "    x_bc_5 = np.ones((num_samples, 1))*(-5)\n",
    "    real_u1_x_val_5 = torch.tensor(real_u1(x_bc_5, t_bc_5, k, omega, r), device=device).float().view(-1, 1)\n",
    "    imag_u1_x_val_5 = torch.tensor(imag_u1(x_bc_5, t_bc_5, k, omega, r), device=device).float().view(-1, 1)\n",
    "    real_v1_x_val_5 = torch.tensor(real_v1(x_bc_5, t_bc_5, k, omega, r), device=device).float().view(-1, 1)\n",
    "    x_t5 = Variable(torch.from_numpy(np.hstack([x_bc_5, t_bc_5])).float(), requires_grad=False).to(device)\n",
    "    #pred_u_r_x_5, pred_u_i_x_5, pred_v_x_5 = shared_model(x_t5)\n",
    "    pred_u_r_x_5, pred_u_i_x_5 = model_u1(x_t5)\n",
    "    pred_v_x_5 = model_v1(x_t5)\n",
    "    boundary_loss_ur_x5 = mse_cost_function(pred_u_r_x_5, real_u1_x_val_5)\n",
    "    boundary_loss_ui_x5 = mse_cost_function(pred_u_i_x_5, imag_u1_x_val_5)\n",
    "    \n",
    "    boundary_loss_v_t_x5 = mse_cost_function(pred_v_x_5, real_v1_x_val_5)\n",
    "    boundary_loss_u_t_x5 = torch.mean(boundary_loss_ur_x5 + boundary_loss_ui_x5)\n",
    "\n",
    "    # boundary loss at x = -4\n",
    "    t_bc_4 = np.random.uniform(0, 1, (num_samples, 1))\n",
    "    x_bc_4 = np.ones((num_samples, 1))*(-4)\n",
    "    real_u1_x_val_4 = torch.tensor(real_u1(x_bc_4, t_bc_4, k, omega, r), device=device).float().view(-1, 1)\n",
    "    imag_u1_x_val_4 = torch.tensor(imag_u1(x_bc_4, t_bc_4, k, omega, r), device=device).float().view(-1, 1)\n",
    "    real_v1_x_val_4 = torch.tensor(real_v1(x_bc_4, t_bc_4, k, omega, r), device=device).float().view(-1, 1)\n",
    "    x_t4 = Variable(torch.from_numpy(np.hstack([x_bc_4, t_bc_4])).float(), requires_grad=False).to(device)\n",
    "    pred_u_r_x_4, pred_u_i_x_4 = model_u1(x_t4)\n",
    "    pred_v_x_4 = model_v1(x_t4)\n",
    "    boundary_loss_ur_x4 = mse_cost_function(pred_u_r_x_4, real_u1_x_val_4)\n",
    "    boundary_loss_ui_x4 = mse_cost_function(pred_u_i_x_4, imag_u1_x_val_4)\n",
    "    \n",
    "    boundary_loss_v_t_x4 = mse_cost_function(pred_v_x_4, real_v1_x_val_4)\n",
    "    boundary_loss_u_t_x4 = torch.mean(boundary_loss_ur_x4 + boundary_loss_ui_x4)\n",
    "    \n",
    "    # Calculate the boundary loss at x = -3\n",
    "    t_bc_3 = np.random.uniform(0, 1, (num_samples, 1))\n",
    "    x_bc_3 = np.ones((num_samples, 1))*(-3)\n",
    "    real_u1_x_val_3 = torch.tensor(real_u1(x_bc_3, t_bc_3, k, omega, r), device=device).float().view(-1, 1)\n",
    "    imag_u1_x_val_3 = torch.tensor(imag_u1(x_bc_3, t_bc_3, k, omega, r), device=device).float().view(-1, 1)\n",
    "    real_v1_x_val_3 = torch.tensor(real_v1(x_bc_3, t_bc_3, k, omega, r), device=device).float().view(-1, 1)\n",
    "    x_t3 = Variable(torch.from_numpy(np.hstack([x_bc_3, t_bc_3])).float(), requires_grad=False).to(device)\n",
    "    pred_u_r_x_3, pred_u_i_x_3 = model_u1(x_t3)\n",
    "    pred_v_x_3 = model_v1(x_t3)\n",
    "    boundary_loss_ur_x3 = mse_cost_function(pred_u_r_x_3, real_u1_x_val_3)\n",
    "    boundary_loss_ui_x3 = mse_cost_function(pred_u_i_x_3, imag_u1_x_val_3)\n",
    "    \n",
    "    boundary_loss_v_t_x3 = mse_cost_function(pred_v_x_3, real_v1_x_val_3)\n",
    "    boundary_loss_u_t_x3 = torch.mean(boundary_loss_ur_x3 + boundary_loss_ui_x3)\n",
    "\n",
    "    # Total loss \n",
    "    loss_u = loss_pde_u + boundary_loss_u_t0 + boundary_loss_u_t_x5 + boundary_loss_u_t_x4 + boundary_loss_u_t_x3\n",
    "    loss_v = loss_pde_v + boundary_loss_v_t0 + boundary_loss_v_t_x5 + boundary_loss_v_t_x4 + boundary_loss_v_t_x3\n",
    "\n",
    "    # Backward pass and optimize\n",
    "    \n",
    "    #loss_u.backward(retain_graph=True)\n",
    "    #optimizer_u1.step()\n",
    "\n",
    "    loss_v.backward()\n",
    "    optimizer_v1.step()\n",
    "    \n",
    "    # Print loss every few epochs\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Epoch {epoch}, Loss U: {loss_u.item()} , Loss V: {loss_v.item()}')\n",
    "        model_u1_filename = os.path.join(model_save_path, f'C_HIGGS_U1_epoch_{epoch}.pth')\n",
    "        torch.save(model_u1.state_dict(), model_u1_filename)\n",
    "        \n",
    "        model_v1_filename = os.path.join(model_save_path, f'C_HIGGS_V1_epoch_{epoch}.pth')\n",
    "        torch.save(model_v1.state_dict(), model_v1_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302f29df-b20d-4bc4-b2f7-13c91cc45444",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
