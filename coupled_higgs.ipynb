{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dc7a86c-65ae-45a3-97c5-67029d2b1726",
   "metadata": {},
   "source": [
    "# Coupled higgs equation \n",
    "$$\n",
    "u_{tt} - u_{xx} + |u|^2 u - 2uv = 0\n",
    "$$\n",
    "$$\n",
    "v_{tt} + v_{xx} - (\\left| u \\right|^2)_{xx} = 0\n",
    "$$\n",
    "\n",
    "where, $ u(x,t) $ represents a complex nucleon field and $ v(x,t) $ represents a real scalar meson field. The coupled Higgs field Equation describes a system of conserved scalar nucleon interaction with a neutral scalar meson.\n",
    "\n",
    "solutions \n",
    "\n",
    "$$\n",
    "u_1(x, t) = ir e^{ir(\\omega x + t)} \\sqrt{1 + \\omega^2} \\tanh\\left(\\frac{r(k + x + \\omega t)}{\\sqrt{2}}\\right)\n",
    "$$\n",
    "$$\n",
    "v_1(x, t) = r^2 \\tanh^2\\left(\\frac{r(k + x + \\omega t)}{\\sqrt{2}}\\right)\n",
    "$$\n",
    "\n",
    "for $t = 0$\n",
    "\n",
    "$$\n",
    "u_1(x, 0) = ir e^{ir \\omega x} \\sqrt{1 + \\omega^2} \\tanh\\left(\\frac{r(k + x)}{\\sqrt{2}}\\right)\n",
    "$$\n",
    "$$\n",
    "v_1(x, 0) = r^2 \\tanh^2\\left(\\frac{r(k + x)}{\\sqrt{2}}\\right)\n",
    "$$\n",
    "\n",
    "where \n",
    "$k = 4, \\omega = 5 , \\alpha = 2, c = 2, r = 2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "658356fb-2ccd-48d1-9492-b36716da03e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.autograd import Variable\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bf1fae9-619d-43f2-bf86-c80d0611c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function class\n",
    "class SinActv(nn.Module):\n",
    "    def forward(self, input_):\n",
    "        return torch.sin(input_)\n",
    "\n",
    "# Base class for shared functionalities\n",
    "class BaseNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseNN, self).__init__()\n",
    "\n",
    "    def _make_layers(self, in_features, out_features, num_layers, activation):\n",
    "        layers = [nn.Linear(in_features, out_features), activation()]\n",
    "        for _ in range(1, num_layers):\n",
    "            layers += [nn.Linear(out_features, out_features), activation()]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "# Model for U1\n",
    "class ModelU1(BaseNN):\n",
    "    def __init__(self, input_dim=2, shared_units=128, branch_units=32, output_dim=1, shared_layers=4, branch_layers=1, activation=nn.Tanh):\n",
    "        super(ModelU1, self).__init__()\n",
    "        self.shared_layers = self._make_layers(input_dim, shared_units, shared_layers, activation)\n",
    "        \n",
    "        # Branch for real part\n",
    "        self.branch_real = self._make_layers(shared_units, branch_units, branch_layers, activation)\n",
    "        self.final_real = nn.Linear(branch_units, output_dim)\n",
    "        \n",
    "        # Branch for imaginary part\n",
    "        self.branch_imag = self._make_layers(shared_units, branch_units, branch_layers, activation)\n",
    "        self.final_imag = nn.Linear(branch_units, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_output = self.shared_layers(x)\n",
    "        u_real = self.final_real(self.branch_real(shared_output))\n",
    "        u_imag = self.final_imag(self.branch_imag(shared_output))\n",
    "        return u_real, u_imag\n",
    "\n",
    "# Model for V1\n",
    "class ModelV1(BaseNN):\n",
    "    def __init__(self, input_dim=2, units=128, output_dim=1, layers=5, activation=nn.Tanh):\n",
    "        super(ModelV1, self).__init__()\n",
    "        self.layers = self._make_layers(input_dim, units, layers, activation)\n",
    "        self.final = nn.Linear(units, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.final(self.layers(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c738f3c7-f37f-4645-af7f-8feea7af94c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(outputs, inputs):\n",
    "    return torch.autograd.grad(outputs, inputs, grad_outputs=torch.ones_like(outputs), create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "def laplacian(field, x, t):\n",
    "    field_x = grad(field, x)\n",
    "    field_xx = grad(field_x, x)\n",
    "    field_t = grad(field, t)\n",
    "    field_tt = grad(field_t, t)\n",
    "    return field_xx, field_tt\n",
    "\n",
    "# Define the ODE system for the Coupled Higgs field equations\n",
    "def coupled_higgs(u_real, u_imag, v, x, t):\n",
    "    u_r_xx, u_r_tt = laplacian(u_real, x, t)\n",
    "    u_i_xx, u_i_tt = laplacian(u_imag, x, t)\n",
    "    v_xx, v_tt = laplacian(v, x, t)\n",
    "\n",
    "    u_abs = u_real**2 + u_imag**2\n",
    "    u_abs_xx, u_abs_tt = laplacian(u_abs, x, t)\n",
    "\n",
    "    # Calculate the field equations\n",
    "    du_eq_r = u_r_tt - u_r_xx + u_abs * u_real - 2 * u_real * v\n",
    "    du_eq_i = u_i_tt - u_i_xx + u_abs * u_imag - 2 * u_imag * v\n",
    "    dv_eq = v_tt + v_xx - u_abs_xx\n",
    "    \n",
    "    return du_eq_r, du_eq_i, dv_eq\n",
    "\n",
    "# Function to calculate the real part of u1\n",
    "def real_u1(x, t, k, omega, r):\n",
    "    return np.real(1j * r * np.exp(1j * r * (omega * x + t)) * np.sqrt(1 + omega**2) *\n",
    "                   np.tanh((r * (k + x + omega * t)) / np.sqrt(2)))\n",
    "\n",
    "def imag_u1(x, t, k, omega, r):\n",
    "    return np.imag(1j * r * np.exp(1j * r * (omega * x + t)) * np.sqrt(1 + omega**2) *\n",
    "                   np.tanh((r * (k + x + omega * t)) / np.sqrt(2)))\n",
    "    \n",
    "def real_v1(x, t, k, omega, r):\n",
    "    return (r * np.tanh((r * (k + x + omega * t)) / np.sqrt(2)) )**2\n",
    "\n",
    "def compute_boundary_loss(model_u1, model_v1, x_boundary, t_boundary, mse_cost_function, k, omega, r):\n",
    "    x_t_boundary = Variable(torch.from_numpy(np.hstack([x_boundary, t_boundary])).float(), requires_grad=False).to(device)\n",
    "    \n",
    "    pred_u_r, pred_u_i = model_u1(x_t_boundary)\n",
    "    pred_v = model_v1(x_t_boundary)\n",
    "\n",
    "    real_u1_val = torch.tensor(real_u1(x_boundary, t_boundary, k, omega, r), device=device).float().view(-1, 1)\n",
    "    imag_u1_val = torch.tensor(imag_u1(x_boundary, t_boundary, k, omega, r), device=device).float().view(-1, 1)\n",
    "    real_v1_val = torch.tensor(real_v1(x_boundary, t_boundary, k, omega, r), device=device).float().view(-1, 1)\n",
    " \n",
    "    boundary_loss_ur = mse_cost_function(pred_u_r, real_u1_val)\n",
    "    boundary_loss_ui = mse_cost_function(pred_u_i, imag_u1_val)\n",
    "    boundary_loss_v = mse_cost_function(pred_v, real_v1_val)\n",
    "    \n",
    "    boundary_loss_u = torch.mean(boundary_loss_ur ** 2 + boundary_loss_ui ** 2)\n",
    "    boundary_loss_v = boundary_loss_v ** 2\n",
    "    \n",
    "    return boundary_loss_u, boundary_loss_v\n",
    "\n",
    "def compute_physics_loss(model_u1, model_v1, x, t, mse_cost_function):\n",
    "    #x_t = Variable(torch.from_numpy(np.hstack([x, t])).float(), requires_grad=True).to(device)\n",
    "    x_t = torch.cat([x, t], dim=1) \n",
    "    pred_u_r, pred_u_i = model_u1(x_t)\n",
    "    pred_v = model_v1(x_t)\n",
    "    \n",
    "    du_eq_r, du_eq_i, dv_eq = coupled_higgs(pred_u_r, pred_u_i, pred_v, x, t)\n",
    "    loss_pde_u = torch.mean(du_eq_r**2 + du_eq_i**2)  \n",
    "    loss_pde_v = torch.mean(dv_eq**2)\n",
    "    \n",
    "    return loss_pde_u, loss_pde_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "054a5b2b-1477-4d49-b696-e61487211c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Training on GPU.\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available and set the default device\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! Training on GPU.\")\n",
    "else:\n",
    "    print(\"CUDA is not available. Training on CPU.\")\n",
    "\n",
    "model_u1 = ModelU1().to(device)\n",
    "model_v1 = ModelV1().to(device)\n",
    "\n",
    "num_epochs = 100000  # Number of training epochs\n",
    "lr = 1e-3          # Learning rate\n",
    "num_samples = 1000 # Number of samples for training\n",
    "k = 4\n",
    "omega = 5\n",
    "r = 2\n",
    "\n",
    "optimizer_u1 = Adam(model_u1.parameters(), lr=lr)\n",
    "optimizer_v1 = Adam(model_v1.parameters(), lr=lr)\n",
    "mse_cost_function = torch.nn.MSELoss()\n",
    "model_save_path = 'model_weights_testing_CHIGGS'\n",
    "os.makedirs(model_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4220620b-b2b9-45f6-90d6-8e6c63ded157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   0%|                      | 3/100000 [00:00<3:07:54,  8.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss U: 14884.6708984375, Loss V: 529.578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   1%|▏                  | 1003/100000 [01:31<2:34:51, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000, Loss U: 2501.1015625, Loss V: 141.20700073242188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   2%|▍                  | 2001/100000 [03:59<5:35:11,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2000, Loss U: 2249.95654296875, Loss V: 208.8144989013672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   3%|▌                  | 3001/100000 [06:56<5:33:24,  4.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3000, Loss U: 2068.539794921875, Loss V: 164.4017791748047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   4%|▊                  | 4001/100000 [10:05<5:29:24,  4.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4000, Loss U: 1997.0330810546875, Loss V: 146.394287109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   5%|▉                  | 5001/100000 [13:42<5:24:16,  4.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5000, Loss U: 2035.63525390625, Loss V: 415.6064147949219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   6%|█▏                 | 6001/100000 [17:03<5:19:42,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6000, Loss U: 1829.7147216796875, Loss V: 241.909912109375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   7%|█▎                 | 7002/100000 [21:42<7:04:56,  3.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7000, Loss U: 1789.26416015625, Loss V: 428.57806396484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   8%|█▌                 | 8002/100000 [27:40<8:48:14,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8000, Loss U: 1777.22900390625, Loss V: 236.46469116210938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::   9%|█▋                 | 9002/100000 [33:39<8:43:51,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9000, Loss U: 1757.2034912109375, Loss V: 172.92938232421875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::  10%|█▊                | 10002/100000 [39:41<8:35:53,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10000, Loss U: 1611.7069091796875, Loss V: 135.1056365966797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::  11%|█▉                | 11002/100000 [45:45<8:42:57,  2.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11000, Loss U: 1821.1822509765625, Loss V: 827.1631469726562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::  12%|██▏               | 12002/100000 [51:47<8:25:08,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12000, Loss U: 1973.291015625, Loss V: 3740.329833984375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::  13%|██▏              | 13001/100000 [57:56<12:32:10,  1.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13000, Loss U: 1565.346923828125, Loss V: 188.55520629882812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::  14%|██▏             | 14002/100000 [1:04:07<8:15:00,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14000, Loss U: 1712.720947265625, Loss V: 446.9079284667969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::  15%|██▍             | 15002/100000 [1:10:20<8:07:42,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15000, Loss U: 1539.1702880859375, Loss V: 218.36563110351562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::  16%|██▌             | 16002/100000 [1:16:35<8:02:10,  2.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16000, Loss U: 1541.4774169921875, Loss V: 118.62850952148438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::  17%|██▋             | 17002/100000 [1:20:39<7:55:42,  2.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17000, Loss U: 1551.0023193359375, Loss V: 106.2322998046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::  18%|██▉             | 18001/100000 [1:24:30<4:39:00,  4.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18000, Loss U: 1523.8262939453125, Loss V: 256.0246276855469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress::  19%|███             | 18844/100000 [1:27:57<3:56:54,  5.71it/s]"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs),desc='Progress:', leave=True, ncols=75, mininterval=0.1, ascii=False):\n",
    "    # Generate random samples for x and t\n",
    "    #x = np.random.uniform(-5, -3, (num_samples, 1))\n",
    "    #t = np.random.uniform(0, 1, (num_samples, 1))\n",
    "    x = (torch.rand(num_samples, 1) * 2 - 5).to(device)  # x in range [-5, -3]\n",
    "    t = (torch.rand(num_samples, 1) * 1).to(device)   \n",
    "    x.requires_grad = True\n",
    "    t.requires_grad = True\n",
    "    x_bc_0 = np.random.uniform(-5, -3, (num_samples, 1))\n",
    "    t_bc_0 = np.zeros((num_samples, 1))\n",
    "    x_bc_5 = np.ones((num_samples, 1))*(-5)\n",
    "    t_bc_5 = np.random.uniform(0, 1, (num_samples, 1))\n",
    "    x_bc_4 = np.ones((num_samples, 1))*(-4)\n",
    "    t_bc_4 = np.random.uniform(0, 1, (num_samples, 1))\n",
    "    x_bc_3 = np.ones((num_samples, 1))*(-3)\n",
    "    t_bc_3 = np.random.uniform(0, 1, (num_samples, 1))\n",
    "    \n",
    "    optimizer_u1.zero_grad()\n",
    "    optimizer_v1.zero_grad()\n",
    "\n",
    "    physics_loss_u, physics_loss_v = compute_physics_loss(model_u1, model_v1, x, t, mse_cost_function)\n",
    "    boundary_loss_u_t0, boundary_loss_v_t0 = compute_boundary_loss(model_u1, model_v1, x_bc_0, t_bc_0, mse_cost_function, k, omega, r)\n",
    "    boundary_loss_u_t5, boundary_loss_v_t5 = compute_boundary_loss(model_u1, model_v1, x_bc_5, t_bc_5, mse_cost_function, k, omega, r)\n",
    "    boundary_loss_u_t4, boundary_loss_v_t4 = compute_boundary_loss(model_u1, model_v1, x_bc_4, t_bc_4, mse_cost_function, k, omega, r)\n",
    "    boundary_loss_u_t3, boundary_loss_v_t3 = compute_boundary_loss(model_u1, model_v1, x_bc_3, t_bc_3, mse_cost_function, k, omega, r)\n",
    "\n",
    "    # Total loss \n",
    "    loss_u = physics_loss_u + boundary_loss_u_t0 + boundary_loss_u_t5 + boundary_loss_u_t4 + boundary_loss_u_t3 \n",
    "    loss_v = physics_loss_v + boundary_loss_v_t0 + boundary_loss_v_t5 + boundary_loss_v_t4 + boundary_loss_v_t3 \n",
    "\n",
    "    total_loss = loss_u + loss_v \n",
    "    total_loss.backward()\n",
    "    optimizer_u1.step()\n",
    "    optimizer_v1.step()\n",
    "    \n",
    "    # Print loss every few epochs\n",
    "    if epoch % 1000 == 0:\n",
    "        print(f'Epoch {epoch}, Loss U: {loss_u.item()}, Loss V: {loss_v.item()}')\n",
    "        model_u1_filename = os.path.join(model_save_path, f'C_HIGGS_U1_epoch_{epoch}.pth')\n",
    "        torch.save(model_u1.state_dict(), model_u1_filename)\n",
    "        \n",
    "        model_v1_filename = os.path.join(model_save_path, f'C_HIGGS_V1_epoch_{epoch}.pth')\n",
    "        torch.save(model_v1.state_dict(), model_v1_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
